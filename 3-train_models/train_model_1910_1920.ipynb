{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from splycer.blocker import BlockDB\n",
    "from splycer.record_set import RecordDB\n",
    "from splycer.pairs_set import PairsDB\n",
    "from splycer.feature_engineer import FeatureEngineer\n",
    "import recordlinkage as rl\n",
    "import pyodbc\n",
    "import numpy as np\n",
    "from xgboost import XGBClassifier\n",
    "from sklearn.metrics import confusion_matrix, precision_score, recall_score, f1_score\n",
    "import pickle as pkl\n",
    "from tqdm import tqdm\n",
    "\n",
    "# Set up a database connection\n",
    "import turbodbc\n",
    "conn = turbodbc.connect('rec_db')\n",
    "\n",
    "import os.path\n",
    "basePath = r'R:\\JoePriceResearch\\record_linking\\projects\\deep_learning\\paper_RR\\CensusTree_2020\\final'\n",
    "trainPath = os.path.abspath(os.path.join(basePath, '2-split_train_test', 'train_1910_1920.csv'))\n",
    "testPath = os.path.abspath(os.path.join(basePath, '2-split_train_test', 'test_1910_1920.csv'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create the class for comparing features."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from recordlinkage.base import BaseCompareFeature\n",
    "\n",
    "class eucledian_distance(BaseCompareFeature):\n",
    "    def __init__(self, left_on, right_on):\n",
    "        super(eucledian_distance, self).__init__(left_on, right_on)\n",
    "        self.n = len(left_on)\n",
    "    def _compute_vectorized(self,*args):\n",
    "        s1 = args[:self.n]\n",
    "        s2 = args[self.n:]\n",
    "        return np.linalg.norm(np.array(s1)-np.array(s2),ord=2,axis=0)\n",
    "    \n",
    "class commonality_weight(BaseCompareFeature):\n",
    "    def __init__(self,left_on,right_on):\n",
    "        super(commonality_weight, self).__init__(left_on, right_on)\n",
    "    def _compute_vectorized(self,s1,s2):\n",
    "        return 1 / np.log1p((s1 + s2) / 2)\n",
    "    \n",
    "def get_compare_engine(drop=[]):\n",
    "    exact_match_features = ['marstat','mbp','fbp','rel','first_nysiis','last_nysiis']\n",
    "    exact_match_features = [feat for feat in exact_match_features if feat not in drop]\n",
    "    c = rl.Compare() # declare comparison object\n",
    "    if 'res' not in drop:\n",
    "        c.geo('res_lat','res_lon','res_lat','res_lon',method = 'exp',scale=500)\n",
    "    if 'bp' not in drop:\n",
    "        c.geo('bp_lat','bp_lon','bp_lat','bp_lon', method = 'exp',scale=500)\n",
    "    if 'first_jaro' not in drop:\n",
    "        c.string('first','first',method = 'jarowinkler')\n",
    "    if 'last_jaro' not in drop:\n",
    "        c.string('last','last', method = 'jarowinkler')\n",
    "    #c.string('first','first',method = 'qgram')\n",
    "    #c.string('last','last', method = 'qgram')\n",
    "    if 'birth_year' not in drop:\n",
    "        c.numeric('birth_year','birth_year', method = 'lin', scale = 1, offset = 1)\n",
    "    if 'immigration' not in drop:\n",
    "        c.numeric('immigration','immigration', method = 'lin', scale = 1, offset = 1)\n",
    "    \n",
    "    vec_cols = [f'occ_vec{i}' for i in range(128)]\n",
    "    if 'occ' not in drop:\n",
    "        c.add(eucledian_distance(vec_cols,vec_cols))\n",
    "    if 'comm_first' not in drop:\n",
    "        c.add(commonality_weight('first_comm','first_comm'))\n",
    "    if 'comm_last' not in drop:\n",
    "        c.add(commonality_weight('last_comm','last_comm'))    \n",
    "    for col in exact_match_features:\n",
    "        c.exact(col,col)\n",
    "    return c"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load the training data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get the training set.\n",
    "df = pd.read_csv(trainPath)\n",
    "\n",
    "# Get the full data using SQL.\n",
    "sql1910 = RecordDB('compiled_1910','ark1910','rec_db')\n",
    "sql1920 = RecordDB('compiled_1920','ark1920','rec_db')\n",
    "rec1910 = sql1910.get_records(df['ark1910'].drop_duplicates()).set_index('index')\n",
    "rec1920 = sql1920.get_records(df['ark1920'].drop_duplicates()).set_index('index')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False    0.931924\n",
       "True     0.068076\n",
       "dtype: float64"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Create the truth value.\n",
    "pairs = pd.MultiIndex.from_arrays((df['ark1910'],df['ark1920']))\n",
    "y = df['ark1920']==df['true_ark_1920']\n",
    "y.value_counts(normalize=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "rec1910.index = rec1910.index_\n",
    "rec1920.index = rec1920.index_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "c = get_compare_engine(drop=['occ','first_nysiis','last_nysiis'])\n",
    "X = c.compute(pairs,rec1910,rec1920)\n",
    "X.columns=['res','bp','first_jaro','last_jaro','birth_year','immigration','first_comm',\n",
    "           'last_comm','marstat','mbp','fbp','rel']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>res</th>\n",
       "      <th>bp</th>\n",
       "      <th>first_jaro</th>\n",
       "      <th>last_jaro</th>\n",
       "      <th>birth_year</th>\n",
       "      <th>immigration</th>\n",
       "      <th>first_comm</th>\n",
       "      <th>last_comm</th>\n",
       "      <th>marstat</th>\n",
       "      <th>mbp</th>\n",
       "      <th>fbp</th>\n",
       "      <th>rel</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>213217.000000</td>\n",
       "      <td>213217.000000</td>\n",
       "      <td>213217.000000</td>\n",
       "      <td>213217.000000</td>\n",
       "      <td>213217.000000</td>\n",
       "      <td>213217.000000</td>\n",
       "      <td>213099.000000</td>\n",
       "      <td>212194.000000</td>\n",
       "      <td>213217.000000</td>\n",
       "      <td>213217.000000</td>\n",
       "      <td>213217.000000</td>\n",
       "      <td>213217.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>0.584990</td>\n",
       "      <td>0.999991</td>\n",
       "      <td>0.919006</td>\n",
       "      <td>0.830371</td>\n",
       "      <td>0.481066</td>\n",
       "      <td>0.027688</td>\n",
       "      <td>0.078902</td>\n",
       "      <td>0.108761</td>\n",
       "      <td>0.735950</td>\n",
       "      <td>0.643457</td>\n",
       "      <td>0.624734</td>\n",
       "      <td>0.695615</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>0.317306</td>\n",
       "      <td>0.003063</td>\n",
       "      <td>0.155184</td>\n",
       "      <td>0.172934</td>\n",
       "      <td>0.443577</td>\n",
       "      <td>0.154307</td>\n",
       "      <td>0.015181</td>\n",
       "      <td>0.044535</td>\n",
       "      <td>0.440827</td>\n",
       "      <td>0.478979</td>\n",
       "      <td>0.484193</td>\n",
       "      <td>0.460147</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.068960</td>\n",
       "      <td>0.072193</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>0.332144</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.885714</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.071743</td>\n",
       "      <td>0.086103</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>0.656111</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.866667</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.076312</td>\n",
       "      <td>0.096981</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>0.842718</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.082698</td>\n",
       "      <td>0.115864</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.442695</td>\n",
       "      <td>1.091357</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                 res             bp     first_jaro      last_jaro  \\\n",
       "count  213217.000000  213217.000000  213217.000000  213217.000000   \n",
       "mean        0.584990       0.999991       0.919006       0.830371   \n",
       "std         0.317306       0.003063       0.155184       0.172934   \n",
       "min         0.000000       0.000000       0.000000       0.000000   \n",
       "25%         0.332144       1.000000       0.885714       0.666667   \n",
       "50%         0.656111       1.000000       1.000000       0.866667   \n",
       "75%         0.842718       1.000000       1.000000       1.000000   \n",
       "max         1.000000       1.000000       1.000000       1.000000   \n",
       "\n",
       "          birth_year    immigration     first_comm      last_comm  \\\n",
       "count  213217.000000  213217.000000  213099.000000  212194.000000   \n",
       "mean        0.481066       0.027688       0.078902       0.108761   \n",
       "std         0.443577       0.154307       0.015181       0.044535   \n",
       "min         0.000000       0.000000       0.068960       0.072193   \n",
       "25%         0.000000       0.000000       0.071743       0.086103   \n",
       "50%         0.500000       0.000000       0.076312       0.096981   \n",
       "75%         1.000000       0.000000       0.082698       0.115864   \n",
       "max         1.000000       1.000000       1.442695       1.091357   \n",
       "\n",
       "             marstat            mbp            fbp            rel  \n",
       "count  213217.000000  213217.000000  213217.000000  213217.000000  \n",
       "mean        0.735950       0.643457       0.624734       0.695615  \n",
       "std         0.440827       0.478979       0.484193       0.460147  \n",
       "min         0.000000       0.000000       0.000000       0.000000  \n",
       "25%         0.000000       0.000000       0.000000       0.000000  \n",
       "50%         1.000000       1.000000       1.000000       1.000000  \n",
       "75%         1.000000       1.000000       1.000000       1.000000  \n",
       "max         1.000000       1.000000       1.000000       1.000000  "
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Loading the test data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>res</th>\n",
       "      <th>bp</th>\n",
       "      <th>first_jaro</th>\n",
       "      <th>last_jaro</th>\n",
       "      <th>birth_year</th>\n",
       "      <th>immigration</th>\n",
       "      <th>first_comm</th>\n",
       "      <th>last_comm</th>\n",
       "      <th>marstat</th>\n",
       "      <th>mbp</th>\n",
       "      <th>fbp</th>\n",
       "      <th>rel</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>91379.000000</td>\n",
       "      <td>91379.000000</td>\n",
       "      <td>91379.000000</td>\n",
       "      <td>91379.000000</td>\n",
       "      <td>91379.000000</td>\n",
       "      <td>91379.000000</td>\n",
       "      <td>91339.000000</td>\n",
       "      <td>90916.000000</td>\n",
       "      <td>91379.000000</td>\n",
       "      <td>91379.000000</td>\n",
       "      <td>91379.000000</td>\n",
       "      <td>91379.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>0.585929</td>\n",
       "      <td>0.999989</td>\n",
       "      <td>0.918454</td>\n",
       "      <td>0.830825</td>\n",
       "      <td>0.478956</td>\n",
       "      <td>0.028765</td>\n",
       "      <td>0.078953</td>\n",
       "      <td>0.108448</td>\n",
       "      <td>0.734315</td>\n",
       "      <td>0.646297</td>\n",
       "      <td>0.627617</td>\n",
       "      <td>0.691505</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>0.317238</td>\n",
       "      <td>0.003308</td>\n",
       "      <td>0.156634</td>\n",
       "      <td>0.172951</td>\n",
       "      <td>0.443120</td>\n",
       "      <td>0.157514</td>\n",
       "      <td>0.015576</td>\n",
       "      <td>0.043669</td>\n",
       "      <td>0.441700</td>\n",
       "      <td>0.478121</td>\n",
       "      <td>0.483442</td>\n",
       "      <td>0.461875</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.068960</td>\n",
       "      <td>0.072193</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>0.335166</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.883333</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.071743</td>\n",
       "      <td>0.086026</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>0.658113</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.866667</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.076323</td>\n",
       "      <td>0.096981</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>0.843234</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.082766</td>\n",
       "      <td>0.115759</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.442695</td>\n",
       "      <td>1.442695</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                res            bp    first_jaro     last_jaro    birth_year  \\\n",
       "count  91379.000000  91379.000000  91379.000000  91379.000000  91379.000000   \n",
       "mean       0.585929      0.999989      0.918454      0.830825      0.478956   \n",
       "std        0.317238      0.003308      0.156634      0.172951      0.443120   \n",
       "min        0.000000      0.000000      0.000000      0.000000      0.000000   \n",
       "25%        0.335166      1.000000      0.883333      0.666667      0.000000   \n",
       "50%        0.658113      1.000000      1.000000      0.866667      0.500000   \n",
       "75%        0.843234      1.000000      1.000000      1.000000      1.000000   \n",
       "max        1.000000      1.000000      1.000000      1.000000      1.000000   \n",
       "\n",
       "        immigration    first_comm     last_comm       marstat           mbp  \\\n",
       "count  91379.000000  91339.000000  90916.000000  91379.000000  91379.000000   \n",
       "mean       0.028765      0.078953      0.108448      0.734315      0.646297   \n",
       "std        0.157514      0.015576      0.043669      0.441700      0.478121   \n",
       "min        0.000000      0.068960      0.072193      0.000000      0.000000   \n",
       "25%        0.000000      0.071743      0.086026      0.000000      0.000000   \n",
       "50%        0.000000      0.076323      0.096981      1.000000      1.000000   \n",
       "75%        0.000000      0.082766      0.115759      1.000000      1.000000   \n",
       "max        1.000000      1.442695      1.442695      1.000000      1.000000   \n",
       "\n",
       "                fbp           rel  \n",
       "count  91379.000000  91379.000000  \n",
       "mean       0.627617      0.691505  \n",
       "std        0.483442      0.461875  \n",
       "min        0.000000      0.000000  \n",
       "25%        0.000000      0.000000  \n",
       "50%        1.000000      1.000000  \n",
       "75%        1.000000      1.000000  \n",
       "max        1.000000      1.000000  "
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Load in the test data.\n",
    "val = pd.read_csv(testPath)\n",
    "val.columns = ['ark1910','ark1920','true_ark1920']\n",
    "\n",
    "val['truth'] = val['ark1920']==val['true_ark1920']\n",
    "pairs = pd.MultiIndex.from_arrays((val['ark1910'],val['ark1920']))\n",
    "\n",
    "recb = sql1920.get_records(val['ark1920'].drop_duplicates().tolist()).set_index('index')\n",
    "reca = sql1910.get_records(val['ark1910'].drop_duplicates().tolist()).set_index('index')\n",
    "reca.index=reca.index_\n",
    "recb.index=recb.index_\n",
    "\n",
    "test_X=c.compute(pairs,reca,recb)\n",
    "\n",
    "test_y = val['truth']\n",
    "test_X.columns=['res','bp','first_jaro','last_jaro','birth_year','immigration','first_comm',\n",
    "           'last_comm','marstat','mbp','fbp','rel']\n",
    "\n",
    "test_X.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train using three algorithms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train_recall: 0.8761970375473648\n",
      "train_precision: 0.22917379944139113\n",
      "\n",
      "val recall: 0.8615755627009646\n",
      "val precision: 0.22727851053903897\n",
      "\n",
      "train_f1_score: 0.3633195257820312\n",
      "test_f1_score: 0.3596764992113829\n"
     ]
    }
   ],
   "source": [
    "# Train on nearest centroid.\n",
    "from sklearn.neighbors import NearestCentroid\n",
    "model = NearestCentroid()\n",
    "model.fit(X.fillna(X.mean()),y)\n",
    "\n",
    "y_pred_val = model.predict(test_X.fillna(X.mean()))\n",
    "y_pred = model.predict(X.fillna(X.mean()))\n",
    "\n",
    "print(f'train_recall: {recall_score(y,y_pred)}')\n",
    "print(f'train_precision: {precision_score(y,y_pred)}\\n')\n",
    "print(f'val recall: {recall_score(test_y,y_pred_val)}')\n",
    "print(f'val precision: {precision_score(test_y,y_pred_val)}\\n')\n",
    "print(f'train_f1_score: {f1_score(y,y_pred)}')\n",
    "print(f'test_f1_score: {f1_score(test_y, y_pred_val)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train_recall: 0.7198759903548054\n",
      "train_precision: 0.833585959313921\n",
      "\n",
      "val recall: 0.7130225080385852\n",
      "val precision: 0.8339601353892441\n",
      "\n",
      "train_f1_score: 0.772569316081331\n",
      "test_f1_score: 0.7687640838966893\n"
     ]
    }
   ],
   "source": [
    "# Train using Logistic Regression\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "model = LogisticRegression(max_iter=300)\n",
    "model.fit(X.fillna(X.mean()),y)\n",
    "\n",
    "# Predict\n",
    "y_pred_val = model.predict(test_X.fillna(X.mean()))\n",
    "y_pred = model.predict(X.fillna(X.mean()))\n",
    "\n",
    "# Print stats.\n",
    "print(f'train_recall: {recall_score(y,y_pred)}')\n",
    "print(f'train_precision: {precision_score(y,y_pred)}\\n')\n",
    "print(f'val recall: {recall_score(test_y,y_pred_val)}')\n",
    "print(f'val precision: {precision_score(test_y,y_pred_val)}\\n')\n",
    "print(f'train_f1_score: {f1_score(y,y_pred)}')\n",
    "print(f'test_f1_score: {f1_score(test_y, y_pred_val)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train_recall: 0.8728212194281777\n",
      "train_precision: 0.9122263824884793\n",
      "\n",
      "test_recall: 0.8364951768488746\n",
      "test_precision: 0.8790336205440108\n",
      "\n",
      "train_f1_score: 0.89208886385241\n",
      "test_f1_score: 0.8572370046956093\n"
     ]
    }
   ],
   "source": [
    "# Train using XGB.\n",
    "model = XGBClassifier()\n",
    "model.fit(X,y)\n",
    "\n",
    "y_pred_val = model.predict(test_X)\n",
    "y_pred = model.predict(X)\n",
    "\n",
    "print(f'train_recall: {recall_score(y,y_pred)}')\n",
    "print(f'train_precision: {precision_score(y,y_pred)}\\n')\n",
    "print(f'test_recall: {recall_score(test_y,y_pred_val)}')\n",
    "print(f'test_precision: {precision_score(test_y,y_pred_val)}\\n')\n",
    "print(f'train_f1_score: {f1_score(y,y_pred)}')\n",
    "print(f'test_f1_score: {f1_score(test_y, y_pred_val)}')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Test micro-parameters for XGBoost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.8543577034283354 0.3 5 0 0\n",
      "0.855352135906317 0.3 5 0 1\n",
      "0.8561275927609288 0.3 5 0.5 0\n",
      "0.8571193144363876 0.3 5 0.5 1\n",
      "0.8588825804328151 0.3 6 0 0\n",
      "0.8572370046956093 0.3 6 0 1\n",
      "0.857919446503583 0.3 6 0.5 0\n",
      "0.8556105610561056 0.3 6 0.5 1\n",
      "0.8568603213844254 0.3 7 0 0\n",
      "0.858433240269338 0.3 7 0 1\n",
      "0.8580363756069459 0.3 7 0.5 0\n",
      "0.8581536942570347 0.3 7 0.5 1\n",
      "0.8577322990592506 0.4 5 0 0\n",
      "0.8566468253968255 0.4 5 0 1\n",
      "0.8578249773606652 0.4 5 0.5 0\n",
      "0.8568603213844254 0.4 5 0.5 1\n",
      "0.8549794238683127 0.4 6 0 0\n",
      "0.8555418211784095 0.4 6 0 1\n",
      "0.8593480581328516 0.4 6 0.5 0\n",
      "0.8583641594739005 0.4 6 0.5 1\n",
      "0.8532586306335996 0.4 7 0 0\n",
      "0.855897351538082 0.4 7 0 1\n",
      "0.8536605451700569 0.4 7 0.5 0\n",
      "0.8590912825568976 0.4 7 0.5 1\n",
      "0.8555390457322105 0.5 5 0 0\n",
      "0.8545949962843695 0.5 5 0 1\n",
      "0.8574259060513497 0.5 5 0.5 0\n",
      "0.856317093311313 0.5 5 0.5 1\n",
      "0.854043392504931 0.5 6 0 0\n",
      "0.8576357512527726 0.5 6 0 1\n",
      "0.8554722885613111 0.5 6 0.5 0\n",
      "0.8576840718168341 0.5 6 0.5 1\n",
      "0.8529290598994809 0.5 7 0 0\n",
      "0.853160613265557 0.5 7 0 1\n",
      "0.8548812664907651 0.5 7 0.5 0\n",
      "0.8526480520550201 0.5 7 0.5 1\n"
     ]
    }
   ],
   "source": [
    "# Check the following micro parameters.\n",
    "learning_rates=[.3,.4,.5]\n",
    "max_depth=[5,6,7]\n",
    "alpha_vals = [0,0.5]\n",
    "lambda_vals = [0,1]\n",
    "n_jobs=16\n",
    "\n",
    "\n",
    "for lr in learning_rates:\n",
    "    for depth in max_depth:\n",
    "        for alph in alpha_vals:\n",
    "            for lam in lambda_vals:\n",
    "                model = XGBClassifier(\n",
    "                    learning_rate=lr, max_depth=depth, n_jobs=n_jobs,\n",
    "                    reg_alpha=alph, reg_lambda=lam)\n",
    "                model.fit(X,y)\n",
    "                y_pred_val = model.predict(test_X)\n",
    "                print(f1_score(test_y, y_pred_val), lr, depth, alph, lam)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ReCreate and save our best model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "XGBClassifier(base_score=0.5, booster='gbtree', colsample_bylevel=1,\n",
       "              colsample_bynode=1, colsample_bytree=1, gamma=0, gpu_id=-1,\n",
       "              importance_type='gain', interaction_constraints='',\n",
       "              learning_rate=0.4, max_delta_step=0, max_depth=6,\n",
       "              min_child_weight=1, missing=nan, monotone_constraints='()',\n",
       "              n_estimators=100, n_jobs=16, num_parallel_tree=1,\n",
       "              objective='binary:logistic', random_state=0, reg_alpha=0.5,\n",
       "              reg_lambda=0, scale_pos_weight=1, subsample=1,\n",
       "              tree_method='exact', validate_parameters=1, verbosity=None)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = XGBClassifier(learning_rate=0.4, max_depth=6, n_jobs=n_jobs,\n",
    "                    reg_alpha=0.5, reg_lambda=0)\n",
    "model.fit(X,y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(84433, 726, 987, 5233)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_pred_val = model.predict(test_X)\n",
    "y_pred = model.predict(X)\n",
    "tn, fp, fn, tp = confusion_matrix(test_y,y_pred_val).ravel()\n",
    "tn, fp, fn, tp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save the model.\n",
    "import pickle\n",
    "pickle.dump(model, open(\"model_1910_1920.dat\", \"wb\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([False, False, False, ..., False, False, False])"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Load the model\n",
    "loaded_model = pickle.load(open(\"model_1910_1920.dat\", \"rb\"))\n",
    "loaded_model.predict(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
