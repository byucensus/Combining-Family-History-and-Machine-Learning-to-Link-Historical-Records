{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from splycer.blocker import BlockDB\n",
    "from splycer.record_set import RecordDB\n",
    "from splycer.pairs_set import PairsDB\n",
    "from splycer.feature_engineer import FeatureEngineer\n",
    "import recordlinkage as rl\n",
    "import pyodbc\n",
    "import numpy as np\n",
    "from xgboost import XGBClassifier\n",
    "from sklearn.metrics import confusion_matrix, precision_score, recall_score, f1_score\n",
    "import pickle as pkl\n",
    "from tqdm import tqdm\n",
    "\n",
    "# Set up a database connection\n",
    "import turbodbc\n",
    "conn = turbodbc.connect('rec_db')\n",
    "\n",
    "import os.path\n",
    "basePath = r'R:\\JoePriceResearch\\record_linking\\projects\\deep_learning\\paper_RR\\CensusTree_2020\\final'\n",
    "trainPath = os.path.abspath(os.path.join(basePath, '2-split_train_test', 'train_1900_1920.csv'))\n",
    "testPath = os.path.abspath(os.path.join(basePath, '2-split_train_test', 'test_1900_1920.csv'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create the class for comparing features."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from recordlinkage.base import BaseCompareFeature\n",
    "\n",
    "class eucledian_distance(BaseCompareFeature):\n",
    "    def __init__(self, left_on, right_on):\n",
    "        super(eucledian_distance, self).__init__(left_on, right_on)\n",
    "        self.n = len(left_on)\n",
    "    def _compute_vectorized(self,*args):\n",
    "        s1 = args[:self.n]\n",
    "        s2 = args[self.n:]\n",
    "        return np.linalg.norm(np.array(s1)-np.array(s2),ord=2,axis=0)\n",
    "    \n",
    "class commonality_weight(BaseCompareFeature):\n",
    "    def __init__(self,left_on,right_on):\n",
    "        super(commonality_weight, self).__init__(left_on, right_on)\n",
    "    def _compute_vectorized(self,s1,s2):\n",
    "        return 1 / np.log1p((s1 + s2) / 2)\n",
    "    \n",
    "def get_compare_engine(drop=[]):\n",
    "    exact_match_features = ['marstat','mbp','fbp','rel','first_nysiis','last_nysiis']\n",
    "    exact_match_features = [feat for feat in exact_match_features if feat not in drop]\n",
    "    c = rl.Compare() # declare comparison object\n",
    "    if 'res' not in drop:\n",
    "        c.geo('res_lat','res_lon','res_lat','res_lon',method = 'exp',scale=500)\n",
    "    if 'bp' not in drop:\n",
    "        c.geo('bp_lat','bp_lon','bp_lat','bp_lon', method = 'exp',scale=500)\n",
    "    if 'first_jaro' not in drop:\n",
    "        c.string('first','first',method = 'jarowinkler')\n",
    "    if 'last_jaro' not in drop:\n",
    "        c.string('last','last', method = 'jarowinkler')\n",
    "    #c.string('first','first',method = 'qgram')\n",
    "    #c.string('last','last', method = 'qgram')\n",
    "    if 'birth_year' not in drop:\n",
    "        c.numeric('birth_year','birth_year', method = 'lin', scale = 1, offset = 1)\n",
    "    if 'immigration' not in drop:\n",
    "        c.numeric('immigration','immigration', method = 'lin', scale = 1, offset = 1)\n",
    "    \n",
    "    vec_cols = [f'occ_vec{i}' for i in range(128)]\n",
    "    if 'occ' not in drop:\n",
    "        c.add(eucledian_distance(vec_cols,vec_cols))\n",
    "    if 'comm_first' not in drop:\n",
    "        c.add(commonality_weight('first_comm','first_comm'))\n",
    "    if 'comm_last' not in drop:\n",
    "        c.add(commonality_weight('last_comm','last_comm'))    \n",
    "    for col in exact_match_features:\n",
    "        c.exact(col,col)\n",
    "    return c"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load the training data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get the training set.\n",
    "df = pd.read_csv(trainPath)\n",
    "\n",
    "# Get the full data using SQL.\n",
    "sql1900 = RecordDB('compiled_1900','ark1900','rec_db')\n",
    "sql1920 = RecordDB('compiled_1920','ark1920','rec_db')\n",
    "rec1900 = sql1900.get_records(df['ark1900'].drop_duplicates()).set_index('index')\n",
    "rec1920 = sql1920.get_records(df['ark1920'].drop_duplicates()).set_index('index')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False    0.874904\n",
       "True     0.125096\n",
       "dtype: float64"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Create the truth value.\n",
    "pairs = pd.MultiIndex.from_arrays((df['ark1900'],df['ark1920']))\n",
    "y = df['ark1920']==df['true_ark_1920']\n",
    "y.value_counts(normalize=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "rec1900.index = rec1900.index_\n",
    "rec1920.index = rec1920.index_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "c = get_compare_engine(drop=['occ','first_nysiis','last_nysiis'])\n",
    "X = c.compute(pairs,rec1900,rec1920)\n",
    "X.columns=['res','bp','first_jaro','last_jaro','birth_year','immigration','first_comm',\n",
    "           'last_comm','marstat','mbp','fbp','rel']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>res</th>\n",
       "      <th>bp</th>\n",
       "      <th>first_jaro</th>\n",
       "      <th>last_jaro</th>\n",
       "      <th>birth_year</th>\n",
       "      <th>immigration</th>\n",
       "      <th>first_comm</th>\n",
       "      <th>last_comm</th>\n",
       "      <th>marstat</th>\n",
       "      <th>mbp</th>\n",
       "      <th>fbp</th>\n",
       "      <th>rel</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>219303.000000</td>\n",
       "      <td>219303.000000</td>\n",
       "      <td>219303.000000</td>\n",
       "      <td>219303.000000</td>\n",
       "      <td>219303.000000</td>\n",
       "      <td>219303.000000</td>\n",
       "      <td>219282.000000</td>\n",
       "      <td>219149.000000</td>\n",
       "      <td>219303.000000</td>\n",
       "      <td>219303.000000</td>\n",
       "      <td>219303.000000</td>\n",
       "      <td>219303.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>0.584706</td>\n",
       "      <td>0.999986</td>\n",
       "      <td>0.937800</td>\n",
       "      <td>0.927219</td>\n",
       "      <td>0.615559</td>\n",
       "      <td>0.042653</td>\n",
       "      <td>0.078292</td>\n",
       "      <td>0.101102</td>\n",
       "      <td>0.617269</td>\n",
       "      <td>0.698394</td>\n",
       "      <td>0.681833</td>\n",
       "      <td>0.588888</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>0.329039</td>\n",
       "      <td>0.003699</td>\n",
       "      <td>0.154777</td>\n",
       "      <td>0.127898</td>\n",
       "      <td>0.412514</td>\n",
       "      <td>0.190296</td>\n",
       "      <td>0.017104</td>\n",
       "      <td>0.035528</td>\n",
       "      <td>0.486055</td>\n",
       "      <td>0.458956</td>\n",
       "      <td>0.465766</td>\n",
       "      <td>0.492037</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.069103</td>\n",
       "      <td>0.072581</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>0.298320</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.900000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.070884</td>\n",
       "      <td>0.080839</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>0.656961</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.074171</td>\n",
       "      <td>0.091911</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>0.868014</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.081370</td>\n",
       "      <td>0.107847</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.442695</td>\n",
       "      <td>1.091357</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                 res             bp     first_jaro      last_jaro  \\\n",
       "count  219303.000000  219303.000000  219303.000000  219303.000000   \n",
       "mean        0.584706       0.999986       0.937800       0.927219   \n",
       "std         0.329039       0.003699       0.154777       0.127898   \n",
       "min         0.000000       0.000000       0.000000       0.000000   \n",
       "25%         0.298320       1.000000       1.000000       0.900000   \n",
       "50%         0.656961       1.000000       1.000000       1.000000   \n",
       "75%         0.868014       1.000000       1.000000       1.000000   \n",
       "max         1.000000       1.000000       1.000000       1.000000   \n",
       "\n",
       "          birth_year    immigration     first_comm      last_comm  \\\n",
       "count  219303.000000  219303.000000  219282.000000  219149.000000   \n",
       "mean        0.615559       0.042653       0.078292       0.101102   \n",
       "std         0.412514       0.190296       0.017104       0.035528   \n",
       "min         0.000000       0.000000       0.069103       0.072581   \n",
       "25%         0.000000       0.000000       0.070884       0.080839   \n",
       "50%         0.500000       0.000000       0.074171       0.091911   \n",
       "75%         1.000000       0.000000       0.081370       0.107847   \n",
       "max         1.000000       1.000000       1.442695       1.091357   \n",
       "\n",
       "             marstat            mbp            fbp            rel  \n",
       "count  219303.000000  219303.000000  219303.000000  219303.000000  \n",
       "mean        0.617269       0.698394       0.681833       0.588888  \n",
       "std         0.486055       0.458956       0.465766       0.492037  \n",
       "min         0.000000       0.000000       0.000000       0.000000  \n",
       "25%         0.000000       0.000000       0.000000       0.000000  \n",
       "50%         1.000000       1.000000       1.000000       1.000000  \n",
       "75%         1.000000       1.000000       1.000000       1.000000  \n",
       "max         1.000000       1.000000       1.000000       1.000000  "
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Loading the test data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>res</th>\n",
       "      <th>bp</th>\n",
       "      <th>first_jaro</th>\n",
       "      <th>last_jaro</th>\n",
       "      <th>birth_year</th>\n",
       "      <th>immigration</th>\n",
       "      <th>first_comm</th>\n",
       "      <th>last_comm</th>\n",
       "      <th>marstat</th>\n",
       "      <th>mbp</th>\n",
       "      <th>fbp</th>\n",
       "      <th>rel</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>93987.000000</td>\n",
       "      <td>93987.000000</td>\n",
       "      <td>93987.000000</td>\n",
       "      <td>93987.000000</td>\n",
       "      <td>93987.000000</td>\n",
       "      <td>93987.000000</td>\n",
       "      <td>93976.000000</td>\n",
       "      <td>93931.000000</td>\n",
       "      <td>93987.000000</td>\n",
       "      <td>93987.000000</td>\n",
       "      <td>93987.000000</td>\n",
       "      <td>93987.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>0.585779</td>\n",
       "      <td>0.999979</td>\n",
       "      <td>0.937040</td>\n",
       "      <td>0.926442</td>\n",
       "      <td>0.617479</td>\n",
       "      <td>0.043389</td>\n",
       "      <td>0.078301</td>\n",
       "      <td>0.101268</td>\n",
       "      <td>0.616809</td>\n",
       "      <td>0.697224</td>\n",
       "      <td>0.681552</td>\n",
       "      <td>0.590060</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>0.328520</td>\n",
       "      <td>0.004613</td>\n",
       "      <td>0.155697</td>\n",
       "      <td>0.128521</td>\n",
       "      <td>0.412936</td>\n",
       "      <td>0.191372</td>\n",
       "      <td>0.017017</td>\n",
       "      <td>0.036013</td>\n",
       "      <td>0.486167</td>\n",
       "      <td>0.459462</td>\n",
       "      <td>0.465877</td>\n",
       "      <td>0.491825</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.069103</td>\n",
       "      <td>0.072581</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>0.300413</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.900000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.070884</td>\n",
       "      <td>0.080840</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>0.658113</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.074171</td>\n",
       "      <td>0.091911</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>0.869093</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.081400</td>\n",
       "      <td>0.108154</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.091357</td>\n",
       "      <td>1.091357</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                res            bp    first_jaro     last_jaro    birth_year  \\\n",
       "count  93987.000000  93987.000000  93987.000000  93987.000000  93987.000000   \n",
       "mean       0.585779      0.999979      0.937040      0.926442      0.617479   \n",
       "std        0.328520      0.004613      0.155697      0.128521      0.412936   \n",
       "min        0.000000      0.000000      0.000000      0.000000      0.000000   \n",
       "25%        0.300413      1.000000      1.000000      0.900000      0.000000   \n",
       "50%        0.658113      1.000000      1.000000      1.000000      0.500000   \n",
       "75%        0.869093      1.000000      1.000000      1.000000      1.000000   \n",
       "max        1.000000      1.000000      1.000000      1.000000      1.000000   \n",
       "\n",
       "        immigration    first_comm     last_comm       marstat           mbp  \\\n",
       "count  93987.000000  93976.000000  93931.000000  93987.000000  93987.000000   \n",
       "mean       0.043389      0.078301      0.101268      0.616809      0.697224   \n",
       "std        0.191372      0.017017      0.036013      0.486167      0.459462   \n",
       "min        0.000000      0.069103      0.072581      0.000000      0.000000   \n",
       "25%        0.000000      0.070884      0.080840      0.000000      0.000000   \n",
       "50%        0.000000      0.074171      0.091911      1.000000      1.000000   \n",
       "75%        0.000000      0.081400      0.108154      1.000000      1.000000   \n",
       "max        1.000000      1.091357      1.091357      1.000000      1.000000   \n",
       "\n",
       "                fbp           rel  \n",
       "count  93987.000000  93987.000000  \n",
       "mean       0.681552      0.590060  \n",
       "std        0.465877      0.491825  \n",
       "min        0.000000      0.000000  \n",
       "25%        0.000000      0.000000  \n",
       "50%        1.000000      1.000000  \n",
       "75%        1.000000      1.000000  \n",
       "max        1.000000      1.000000  "
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Load in the test data.\n",
    "val = pd.read_csv(testPath)\n",
    "val.columns = ['ark1900','ark1920','true_ark1920']\n",
    "\n",
    "val['truth'] = val['ark1920']==val['true_ark1920']\n",
    "pairs = pd.MultiIndex.from_arrays((val['ark1900'],val['ark1920']))\n",
    "\n",
    "recb = sql1920.get_records(val['ark1920'].drop_duplicates().tolist()).set_index('index')\n",
    "reca = sql1900.get_records(val['ark1900'].drop_duplicates().tolist()).set_index('index')\n",
    "reca.index=reca.index_\n",
    "recb.index=recb.index_\n",
    "\n",
    "test_X=c.compute(pairs,reca,recb)\n",
    "\n",
    "test_y = val['truth']\n",
    "test_X.columns=['res','bp','first_jaro','last_jaro','birth_year','immigration','first_comm',\n",
    "           'last_comm','marstat','mbp','fbp','rel']\n",
    "\n",
    "test_X.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train using three algorithms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train_recall: 0.8033462127287307\n",
      "train_precision: 0.28021614748887474\n",
      "\n",
      "val recall: 0.7983385606510129\n",
      "val precision: 0.2783096926713948\n",
      "\n",
      "train_f1_score: 0.41550092379623693\n",
      "test_f1_score: 0.41273528058373693\n"
     ]
    }
   ],
   "source": [
    "# Train on nearest centroid.\n",
    "from sklearn.neighbors import NearestCentroid\n",
    "model = NearestCentroid()\n",
    "model.fit(X.fillna(X.mean()),y)\n",
    "\n",
    "y_pred_val = model.predict(test_X.fillna(X.mean()))\n",
    "y_pred = model.predict(X.fillna(X.mean()))\n",
    "\n",
    "print(f'train_recall: {recall_score(y,y_pred)}')\n",
    "print(f'train_precision: {precision_score(y,y_pred)}\\n')\n",
    "print(f'val recall: {recall_score(test_y,y_pred_val)}')\n",
    "print(f'val precision: {precision_score(test_y,y_pred_val)}\\n')\n",
    "print(f'train_f1_score: {f1_score(y,y_pred)}')\n",
    "print(f'test_f1_score: {f1_score(test_y, y_pred_val)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train_recall: 0.6241160603630531\n",
      "train_precision: 0.8327821011673152\n",
      "\n",
      "val recall: 0.6261761464779181\n",
      "val precision: 0.8293477040529921\n",
      "\n",
      "train_f1_score: 0.7135058548985289\n",
      "test_f1_score: 0.7135819165378671\n"
     ]
    }
   ],
   "source": [
    "# Train using Logistic Regression\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "model = LogisticRegression(max_iter=300)\n",
    "model.fit(X.fillna(X.mean()),y)\n",
    "\n",
    "# Predict\n",
    "y_pred_val = model.predict(test_X.fillna(X.mean()))\n",
    "y_pred = model.predict(X.fillna(X.mean()))\n",
    "\n",
    "# Print stats.\n",
    "print(f'train_recall: {recall_score(y,y_pred)}')\n",
    "print(f'train_precision: {precision_score(y,y_pred)}\\n')\n",
    "print(f'val recall: {recall_score(test_y,y_pred_val)}')\n",
    "print(f'val precision: {precision_score(test_y,y_pred_val)}\\n')\n",
    "print(f'train_f1_score: {f1_score(y,y_pred)}')\n",
    "print(f'test_f1_score: {f1_score(test_y, y_pred_val)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train_recall: 0.8225924035867901\n",
      "train_precision: 0.8801138801138801\n",
      "\n",
      "test_recall: 0.78697974061202\n",
      "test_precision: 0.8601074671113582\n",
      "\n",
      "train_f1_score: 0.8503815355628828\n",
      "test_f1_score: 0.8219202337213936\n"
     ]
    }
   ],
   "source": [
    "# Train using XGB.\n",
    "model = XGBClassifier()\n",
    "model.fit(X,y)\n",
    "\n",
    "y_pred_val = model.predict(test_X)\n",
    "y_pred = model.predict(X)\n",
    "\n",
    "print(f'train_recall: {recall_score(y,y_pred)}')\n",
    "print(f'train_precision: {precision_score(y,y_pred)}\\n')\n",
    "print(f'test_recall: {recall_score(test_y,y_pred_val)}')\n",
    "print(f'test_precision: {precision_score(test_y,y_pred_val)}\\n')\n",
    "print(f'train_f1_score: {f1_score(y,y_pred)}')\n",
    "print(f'test_f1_score: {f1_score(test_y, y_pred_val)}')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Test micro-parameters for XGBoost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.8178675884073385 0.3 5 0 0\n",
      "0.8210078823841999 0.3 5 0 1\n",
      "0.8192856509793495 0.3 5 0.5 0\n",
      "0.819473334808586 0.3 5 0.5 1\n",
      "0.8238571049606509 0.3 6 0 0\n",
      "0.8219202337213936 0.3 6 0 1\n",
      "0.8223027304055845 0.3 6 0.5 0\n",
      "0.8228010436474593 0.3 6 0.5 1\n",
      "0.8210917784566344 0.4 5 0 0\n",
      "0.8227534307215583 0.4 5 0 1\n",
      "0.8223910930458602 0.4 5 0.5 0\n",
      "0.8223951883955423 0.4 5 0.5 1\n",
      "0.8238985372751778 0.4 6 0 0\n",
      "0.8264032805679262 0.4 6 0 1\n",
      "0.8246721709567751 0.4 6 0.5 0\n",
      "0.8263283108643935 0.4 6 0.5 1\n"
     ]
    }
   ],
   "source": [
    "# Check the following micro parameters.\n",
    "learning_rates=[.3,.4]\n",
    "max_depth=[5,6]\n",
    "alpha_vals = [0,0.5]\n",
    "lambda_vals = [0,1]\n",
    "n_jobs=16\n",
    "\n",
    "\n",
    "for lr in learning_rates:\n",
    "    for depth in max_depth:\n",
    "        for alph in alpha_vals:\n",
    "            for lam in lambda_vals:\n",
    "                model = XGBClassifier(\n",
    "                    learning_rate=lr, max_depth=depth, n_jobs=n_jobs,\n",
    "                    reg_alpha=alph, reg_lambda=lam)\n",
    "                model.fit(X,y)\n",
    "                y_pred_val = model.predict(test_X)\n",
    "                print(f1_score(test_y, y_pred_val), lr, depth, alph, lam)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ReCreate and save our best model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "XGBClassifier(base_score=0.5, booster='gbtree', colsample_bylevel=1,\n",
       "              colsample_bynode=1, colsample_bytree=1, gamma=0, gpu_id=-1,\n",
       "              importance_type='gain', interaction_constraints='',\n",
       "              learning_rate=0.4, max_delta_step=0, max_depth=6,\n",
       "              min_child_weight=1, missing=nan, monotone_constraints='()',\n",
       "              n_estimators=100, n_jobs=16, num_parallel_tree=1,\n",
       "              objective='binary:logistic', random_state=0, reg_alpha=0,\n",
       "              reg_lambda=1, scale_pos_weight=1, subsample=1,\n",
       "              tree_method='exact', validate_parameters=1, verbosity=None)"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = XGBClassifier(learning_rate=0.4, max_depth=6, n_jobs=n_jobs,\n",
    "                    reg_alpha=0, reg_lambda=1)\n",
    "model.fit(X,y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(80679, 1511, 2426, 9371)"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_pred_val = model.predict(test_X)\n",
    "y_pred = model.predict(X)\n",
    "tn, fp, fn, tp = confusion_matrix(test_y,y_pred_val).ravel()\n",
    "tn, fp, fn, tp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save the model.\n",
    "import pickle\n",
    "pickle.dump(model, open(\"model_1900_1920.dat\", \"wb\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([False, False, False, ...,  True, False, False])"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Load the model\n",
    "loaded_model = pickle.load(open(\"model_1900_1920.dat\", \"rb\"))\n",
    "loaded_model.predict(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
