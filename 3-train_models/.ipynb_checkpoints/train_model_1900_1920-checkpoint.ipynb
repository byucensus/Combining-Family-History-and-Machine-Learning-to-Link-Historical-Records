{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from splycer.blocker import BlockDB\n",
    "from splycer.record_set import RecordDB\n",
    "from splycer.pairs_set import PairsDB\n",
    "from splycer.feature_engineer import FeatureEngineer\n",
    "import recordlinkage as rl\n",
    "import pyodbc\n",
    "import numpy as np\n",
    "from xgboost import XGBClassifier\n",
    "from sklearn.metrics import confusion_matrix, precision_score, recall_score, f1_score\n",
    "import pickle as pkl\n",
    "from tqdm import tqdm\n",
    "\n",
    "# Set up a database connection\n",
    "import turbodbc\n",
    "conn = turbodbc.connect('rec_db')\n",
    "\n",
    "import os.path\n",
    "basePath = r'R:\\JoePriceResearch\\record_linking\\projects\\deep_learning\\paper_RR\\CensusTree_2020\\final'\n",
    "trainPath = os.path.abspath(os.path.join(basePath, '2-split_train_test', 'train_1910_1920.csv'))\n",
    "testPath = os.path.abspath(os.path.join(basePath, '2-split_train_test', 'test_1910_1920.csv'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create the class for comparing features."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from recordlinkage.base import BaseCompareFeature\n",
    "\n",
    "class eucledian_distance(BaseCompareFeature):\n",
    "    def __init__(self, left_on, right_on):\n",
    "        super(eucledian_distance, self).__init__(left_on, right_on)\n",
    "        self.n = len(left_on)\n",
    "    def _compute_vectorized(self,*args):\n",
    "        s1 = args[:self.n]\n",
    "        s2 = args[self.n:]\n",
    "        return np.linalg.norm(np.array(s1)-np.array(s2),ord=2,axis=0)\n",
    "    \n",
    "class commonality_weight(BaseCompareFeature):\n",
    "    def __init__(self,left_on,right_on):\n",
    "        super(commonality_weight, self).__init__(left_on, right_on)\n",
    "    def _compute_vectorized(self,s1,s2):\n",
    "        return 1 / np.log1p((s1 + s2) / 2)\n",
    "    \n",
    "def get_compare_engine(drop=[]):\n",
    "    exact_match_features = ['marstat','mbp','fbp','rel','first_nysiis','last_nysiis']\n",
    "    exact_match_features = [feat for feat in exact_match_features if feat not in drop]\n",
    "    c = rl.Compare() # declare comparison object\n",
    "    if 'res' not in drop:\n",
    "        c.geo('res_lat','res_lon','res_lat','res_lon',method = 'exp',scale=500)\n",
    "    if 'bp' not in drop:\n",
    "        c.geo('bp_lat','bp_lon','bp_lat','bp_lon', method = 'exp',scale=500)\n",
    "    if 'first_jaro' not in drop:\n",
    "        c.string('first','first',method = 'jarowinkler')\n",
    "    if 'last_jaro' not in drop:\n",
    "        c.string('last','last', method = 'jarowinkler')\n",
    "    #c.string('first','first',method = 'qgram')\n",
    "    #c.string('last','last', method = 'qgram')\n",
    "    if 'birth_year' not in drop:\n",
    "        c.numeric('birth_year','birth_year', method = 'lin', scale = 1, offset = 1)\n",
    "    if 'immigration' not in drop:\n",
    "        c.numeric('immigration','immigration', method = 'lin', scale = 1, offset = 1)\n",
    "    \n",
    "    vec_cols = [f'occ_vec{i}' for i in range(128)]\n",
    "    if 'occ' not in drop:\n",
    "        c.add(eucledian_distance(vec_cols,vec_cols))\n",
    "    if 'comm_first' not in drop:\n",
    "        c.add(commonality_weight('first_comm','first_comm'))\n",
    "    if 'comm_last' not in drop:\n",
    "        c.add(commonality_weight('last_comm','last_comm'))    \n",
    "    for col in exact_match_features:\n",
    "        c.exact(col,col)\n",
    "    return c"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load the training data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get the training set.\n",
    "df = pd.read_csv(trainPath)\n",
    "\n",
    "# Get the full data using SQL.\n",
    "sql1910 = RecordDB('compiled_1910','ark1910','rec_db')\n",
    "sql1920 = RecordDB('compiled_1920','ark1920','rec_db')\n",
    "rec1910 = sql1910.get_records(df['ark1910'].drop_duplicates()).set_index('index')\n",
    "rec1920 = sql1920.get_records(df['ark1920'].drop_duplicates()).set_index('index')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False    0.931924\n",
       "True     0.068076\n",
       "dtype: float64"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Create the truth value.\n",
    "pairs = pd.MultiIndex.from_arrays((df['ark1910'],df['ark1920']))\n",
    "y = df['ark1920']==df['true_ark_1920']\n",
    "y.value_counts(normalize=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "rec1910.index = rec1910.index_\n",
    "rec1920.index = rec1920.index_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "c = get_compare_engine(drop=['occ','first_nysiis','last_nysiis'])\n",
    "X = c.compute(pairs,rec1910,rec1920)\n",
    "X.columns=['res','bp','first_jaro','last_jaro','birth_year','immigration','first_comm',\n",
    "           'last_comm','marstat','mbp','fbp','rel']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>res</th>\n",
       "      <th>bp</th>\n",
       "      <th>first_jaro</th>\n",
       "      <th>last_jaro</th>\n",
       "      <th>birth_year</th>\n",
       "      <th>immigration</th>\n",
       "      <th>first_comm</th>\n",
       "      <th>last_comm</th>\n",
       "      <th>marstat</th>\n",
       "      <th>mbp</th>\n",
       "      <th>fbp</th>\n",
       "      <th>rel</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>213217.000000</td>\n",
       "      <td>213217.000000</td>\n",
       "      <td>213217.000000</td>\n",
       "      <td>213217.000000</td>\n",
       "      <td>213217.000000</td>\n",
       "      <td>213217.000000</td>\n",
       "      <td>213217.000000</td>\n",
       "      <td>213217.000000</td>\n",
       "      <td>213217.000000</td>\n",
       "      <td>213217.000000</td>\n",
       "      <td>213217.000000</td>\n",
       "      <td>213217.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>0.584990</td>\n",
       "      <td>0.999991</td>\n",
       "      <td>0.919006</td>\n",
       "      <td>0.830371</td>\n",
       "      <td>0.481066</td>\n",
       "      <td>0.027688</td>\n",
       "      <td>0.078305</td>\n",
       "      <td>0.103442</td>\n",
       "      <td>0.735950</td>\n",
       "      <td>0.643457</td>\n",
       "      <td>0.624734</td>\n",
       "      <td>0.695615</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>0.317306</td>\n",
       "      <td>0.003063</td>\n",
       "      <td>0.155184</td>\n",
       "      <td>0.172934</td>\n",
       "      <td>0.443577</td>\n",
       "      <td>0.154307</td>\n",
       "      <td>0.029566</td>\n",
       "      <td>0.088566</td>\n",
       "      <td>0.440827</td>\n",
       "      <td>0.478979</td>\n",
       "      <td>0.484193</td>\n",
       "      <td>0.460147</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-1.000000</td>\n",
       "      <td>-1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>0.332144</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.885714</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.071743</td>\n",
       "      <td>0.085940</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>0.656111</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.866667</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.076312</td>\n",
       "      <td>0.096830</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>0.842718</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.082698</td>\n",
       "      <td>0.115680</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.442695</td>\n",
       "      <td>1.091357</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                 res             bp     first_jaro      last_jaro  \\\n",
       "count  213217.000000  213217.000000  213217.000000  213217.000000   \n",
       "mean        0.584990       0.999991       0.919006       0.830371   \n",
       "std         0.317306       0.003063       0.155184       0.172934   \n",
       "min         0.000000       0.000000       0.000000       0.000000   \n",
       "25%         0.332144       1.000000       0.885714       0.666667   \n",
       "50%         0.656111       1.000000       1.000000       0.866667   \n",
       "75%         0.842718       1.000000       1.000000       1.000000   \n",
       "max         1.000000       1.000000       1.000000       1.000000   \n",
       "\n",
       "          birth_year    immigration     first_comm      last_comm  \\\n",
       "count  213217.000000  213217.000000  213217.000000  213217.000000   \n",
       "mean        0.481066       0.027688       0.078305       0.103442   \n",
       "std         0.443577       0.154307       0.029566       0.088566   \n",
       "min         0.000000       0.000000      -1.000000      -1.000000   \n",
       "25%         0.000000       0.000000       0.071743       0.085940   \n",
       "50%         0.500000       0.000000       0.076312       0.096830   \n",
       "75%         1.000000       0.000000       0.082698       0.115680   \n",
       "max         1.000000       1.000000       1.442695       1.091357   \n",
       "\n",
       "             marstat            mbp            fbp            rel  \n",
       "count  213217.000000  213217.000000  213217.000000  213217.000000  \n",
       "mean        0.735950       0.643457       0.624734       0.695615  \n",
       "std         0.440827       0.478979       0.484193       0.460147  \n",
       "min         0.000000       0.000000       0.000000       0.000000  \n",
       "25%         0.000000       0.000000       0.000000       0.000000  \n",
       "50%         1.000000       1.000000       1.000000       1.000000  \n",
       "75%         1.000000       1.000000       1.000000       1.000000  \n",
       "max         1.000000       1.000000       1.000000       1.000000  "
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Loading the test data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>res</th>\n",
       "      <th>bp</th>\n",
       "      <th>first_jaro</th>\n",
       "      <th>last_jaro</th>\n",
       "      <th>birth_year</th>\n",
       "      <th>immigration</th>\n",
       "      <th>first_comm</th>\n",
       "      <th>last_comm</th>\n",
       "      <th>marstat</th>\n",
       "      <th>mbp</th>\n",
       "      <th>fbp</th>\n",
       "      <th>rel</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>91379.000000</td>\n",
       "      <td>91379.000000</td>\n",
       "      <td>91379.000000</td>\n",
       "      <td>91379.000000</td>\n",
       "      <td>91379.000000</td>\n",
       "      <td>91379.000000</td>\n",
       "      <td>91379.000000</td>\n",
       "      <td>91379.000000</td>\n",
       "      <td>91379.000000</td>\n",
       "      <td>91379.000000</td>\n",
       "      <td>91379.000000</td>\n",
       "      <td>91379.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>0.585929</td>\n",
       "      <td>0.999989</td>\n",
       "      <td>0.918454</td>\n",
       "      <td>0.830825</td>\n",
       "      <td>0.478956</td>\n",
       "      <td>0.028765</td>\n",
       "      <td>0.078480</td>\n",
       "      <td>0.102832</td>\n",
       "      <td>0.734315</td>\n",
       "      <td>0.646297</td>\n",
       "      <td>0.627617</td>\n",
       "      <td>0.691505</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>0.317238</td>\n",
       "      <td>0.003308</td>\n",
       "      <td>0.156634</td>\n",
       "      <td>0.172951</td>\n",
       "      <td>0.443120</td>\n",
       "      <td>0.157514</td>\n",
       "      <td>0.027420</td>\n",
       "      <td>0.089951</td>\n",
       "      <td>0.441700</td>\n",
       "      <td>0.478121</td>\n",
       "      <td>0.483442</td>\n",
       "      <td>0.461875</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-1.000000</td>\n",
       "      <td>-1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>0.335166</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.883333</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.071743</td>\n",
       "      <td>0.085940</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>0.658113</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.866667</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.076323</td>\n",
       "      <td>0.096814</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>0.843234</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.082756</td>\n",
       "      <td>0.115596</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.442695</td>\n",
       "      <td>1.442695</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                res            bp    first_jaro     last_jaro    birth_year  \\\n",
       "count  91379.000000  91379.000000  91379.000000  91379.000000  91379.000000   \n",
       "mean       0.585929      0.999989      0.918454      0.830825      0.478956   \n",
       "std        0.317238      0.003308      0.156634      0.172951      0.443120   \n",
       "min        0.000000      0.000000      0.000000      0.000000      0.000000   \n",
       "25%        0.335166      1.000000      0.883333      0.666667      0.000000   \n",
       "50%        0.658113      1.000000      1.000000      0.866667      0.500000   \n",
       "75%        0.843234      1.000000      1.000000      1.000000      1.000000   \n",
       "max        1.000000      1.000000      1.000000      1.000000      1.000000   \n",
       "\n",
       "        immigration    first_comm     last_comm       marstat           mbp  \\\n",
       "count  91379.000000  91379.000000  91379.000000  91379.000000  91379.000000   \n",
       "mean       0.028765      0.078480      0.102832      0.734315      0.646297   \n",
       "std        0.157514      0.027420      0.089951      0.441700      0.478121   \n",
       "min        0.000000     -1.000000     -1.000000      0.000000      0.000000   \n",
       "25%        0.000000      0.071743      0.085940      0.000000      0.000000   \n",
       "50%        0.000000      0.076323      0.096814      1.000000      1.000000   \n",
       "75%        0.000000      0.082756      0.115596      1.000000      1.000000   \n",
       "max        1.000000      1.442695      1.442695      1.000000      1.000000   \n",
       "\n",
       "                fbp           rel  \n",
       "count  91379.000000  91379.000000  \n",
       "mean       0.627617      0.691505  \n",
       "std        0.483442      0.461875  \n",
       "min        0.000000      0.000000  \n",
       "25%        0.000000      0.000000  \n",
       "50%        1.000000      1.000000  \n",
       "75%        1.000000      1.000000  \n",
       "max        1.000000      1.000000  "
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Load in the test data.\n",
    "val = pd.read_csv(testPath)\n",
    "val.columns = ['ark1910','ark1920','true_ark1920']\n",
    "\n",
    "val['truth'] = val['ark1920']==val['true_ark1920']\n",
    "pairs = pd.MultiIndex.from_arrays((val['ark1910'],val['ark1920']))\n",
    "\n",
    "recb = sql1920.get_records(val['ark1920'].drop_duplicates().tolist()).set_index('index')\n",
    "reca = sql1910.get_records(val['ark1910'].drop_duplicates().tolist()).set_index('index')\n",
    "reca.index=reca.index_\n",
    "recb.index=recb.index_\n",
    "\n",
    "test_X=c.compute(pairs,reca,recb)\n",
    "\n",
    "test_y = val['truth']\n",
    "test_X.columns=['res','bp','first_jaro','last_jaro','birth_year','immigration','first_comm',\n",
    "           'last_comm','marstat','mbp','fbp','rel']\n",
    "\n",
    "test_X.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train using three algorithms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train_recall: 0.8761970375473648\n",
      "train_precision: 0.22924402465842317\n",
      "\n",
      "val recall: 0.8615755627009646\n",
      "val precision: 0.2272592341291718\n",
      "\n",
      "train_f1_score: 0.36340776934836344\n",
      "test_f1_score: 0.3596523606590383\n"
     ]
    }
   ],
   "source": [
    "# Train on nearest centroid.\n",
    "from sklearn.neighbors import NearestCentroid\n",
    "model = NearestCentroid()\n",
    "model.fit(X.fillna(X.mean()),y)\n",
    "\n",
    "y_pred_val = model.predict(X_val.fillna(X.mean()))\n",
    "y_pred = model.predict(X.fillna(X.mean()))\n",
    "print(f'train_recall: {recall_score(y,y_pred)}')\n",
    "print(f'train_precision: {precision_score(y,y_pred)}\\n')\n",
    "print(f'val recall: {recall_score(y_val,y_pred_val)}')\n",
    "print(f'val precision: {precision_score(y_val,y_pred_val)}\\n')\n",
    "print(f'train_f1_score: {f1_score(y,y_pred)}')\n",
    "print(f'test_f1_score: {f1_score(y_val, y_pred_val)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train_recall: 0.712090940406476\n",
      "train_precision: 0.8290687414775006\n",
      "\n",
      "val recall: 0.7016077170418007\n",
      "val precision: 0.8271417740712661\n",
      "\n",
      "train_f1_score: 0.7661403898895559\n",
      "test_f1_score: 0.7592205984690327\n"
     ]
    }
   ],
   "source": [
    "# Train using Logistic Regression\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "model = LogisticRegression(max_iter=300)\n",
    "model.fit(X.fillna(X.mean()),y)\n",
    "\n",
    "# Predict\n",
    "y_pred_val = model.predict(test_X.fillna(X.mean()))\n",
    "y_pred = model.predict(X.fillna(X.mean()))\n",
    "\n",
    "# Print stats.\n",
    "print(f'train_recall: {recall_score(y,y_pred)}')\n",
    "print(f'train_precision: {precision_score(y,y_pred)}\\n')\n",
    "print(f'val recall: {recall_score(y_val,y_pred_val)}')\n",
    "print(f'val precision: {precision_score(y_val,y_pred_val)}\\n')\n",
    "print(f'train_f1_score: {f1_score(y,y_pred)}')\n",
    "print(f'test_f1_score: {f1_score(y_val, y_pred_val)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train_recall: 0.871098863244919\n",
      "train_precision: 0.9102296450939458\n",
      "\n",
      "test_recall: 0.8353697749196142\n",
      "test_precision: 0.8788903924221921\n",
      "\n",
      "train_f1_score: 0.890234457508977\n",
      "test_f1_score: 0.8565776458951534\n"
     ]
    }
   ],
   "source": [
    "# Train using XGB.\n",
    "model = XGBClassifier()\n",
    "model.fit(X,y)\n",
    "\n",
    "y_pred_val = model.predict(X_val)\n",
    "y_pred = model.predict(X)\n",
    "\n",
    "print(f'train_recall: {recall_score(y,y_pred)}')\n",
    "print(f'train_precision: {precision_score(y,y_pred)}\\n')\n",
    "print(f'test_recall: {recall_score(y_val,y_pred_val)}')\n",
    "print(f'test_precision: {precision_score(y_val,y_pred_val)}\\n')\n",
    "print(f'train_f1_score: {f1_score(y,y_pred)}')\n",
    "print(f'test_f1_score: {f1_score(y_val, y_pred_val)}')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Test micro-parameters for XGBoost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.8544973544973544 0.3 5 0 0\n",
      "0.8561287659925713 0.3 5 0 1\n",
      "0.8568358406348157 0.3 5 0.5 0\n",
      "0.8550449632868574 0.3 5 0.5 1\n",
      "0.8612873980054397 0.3 6 0 0\n",
      "0.8565776458951534 0.3 6 0 1\n",
      "0.8581326294952162 0.3 6 0.5 0\n",
      "0.85718983803338 0.3 6 0.5 1\n",
      "0.8558262014483213 0.3 7 0 0\n",
      "0.8556624722427831 0.3 7 0 1\n",
      "0.8549542871262664 0.3 7 0.5 0\n",
      "0.8584542250635194 0.3 7 0.5 1\n",
      "0.8562711305351695 0.4 5 0 0\n",
      "0.8568836096675739 0.4 5 0 1\n",
      "0.8581525312294545 0.4 5 0.5 0\n",
      "0.8567183889072301 0.4 5 0.5 1\n",
      "0.8568604842694779 0.4 6 0 0\n"
     ]
    }
   ],
   "source": [
    "# Check the following micro parameters.\n",
    "learning_rates=[.3,.4,.5]\n",
    "max_depth=[5,6,7]\n",
    "alpha_vals = [0,0.5]\n",
    "lambda_vals = [0,1]\n",
    "n_jobs=16\n",
    "\n",
    "\n",
    "for lr in learning_rates:\n",
    "    for depth in max_depth:\n",
    "        for alph in alpha_vals:\n",
    "            for lam in lambda_vals:\n",
    "                model = XGBClassifier(\n",
    "                    learning_rate=lr, max_depth=depth, n_jobs=n_jobs,\n",
    "                    reg_alpha=alph, reg_lambda=lam)\n",
    "                model.fit(X,y)\n",
    "                y_pred_val = model.predict(X_val)\n",
    "                print(f1_score(y_val, y_pred_val), lr, depth, alph, lam)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ReCreate and save our best model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = XGBClassifier()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(84429, 730, 1042, 5178)"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tn, fp, fn, tp = confusion_matrix(y_val,y_pred_val).ravel()\n",
    "tn, fp, fn, tp"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
