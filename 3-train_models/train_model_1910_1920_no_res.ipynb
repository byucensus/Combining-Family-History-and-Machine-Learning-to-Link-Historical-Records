{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from splycer.blocker import BlockDB\n",
    "from splycer.record_set import RecordDB\n",
    "from splycer.pairs_set import PairsDB\n",
    "from splycer.feature_engineer import FeatureEngineer\n",
    "import recordlinkage as rl\n",
    "import pyodbc\n",
    "import numpy as np\n",
    "from xgboost import XGBClassifier\n",
    "from sklearn.metrics import confusion_matrix, precision_score, recall_score, f1_score\n",
    "import pickle as pkl\n",
    "from tqdm import tqdm\n",
    "\n",
    "# Set up a database connection\n",
    "import turbodbc\n",
    "conn = turbodbc.connect('rec_db')\n",
    "\n",
    "import os.path\n",
    "basePath = r'R:\\JoePriceResearch\\record_linking\\projects\\deep_learning\\paper_RR\\CensusTree_2020\\final'\n",
    "trainPath = os.path.abspath(os.path.join(basePath, '2-split_train_test', 'train_1910_1920.csv'))\n",
    "testPath = os.path.abspath(os.path.join(basePath, '2-split_train_test', 'test_1910_1920.csv'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create the class for comparing features."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from recordlinkage.base import BaseCompareFeature\n",
    "\n",
    "class eucledian_distance(BaseCompareFeature):\n",
    "    def __init__(self, left_on, right_on):\n",
    "        super(eucledian_distance, self).__init__(left_on, right_on)\n",
    "        self.n = len(left_on)\n",
    "    def _compute_vectorized(self,*args):\n",
    "        s1 = args[:self.n]\n",
    "        s2 = args[self.n:]\n",
    "        return np.linalg.norm(np.array(s1)-np.array(s2),ord=2,axis=0)\n",
    "    \n",
    "class commonality_weight(BaseCompareFeature):\n",
    "    def __init__(self,left_on,right_on):\n",
    "        super(commonality_weight, self).__init__(left_on, right_on)\n",
    "    def _compute_vectorized(self,s1,s2):\n",
    "        return 1 / np.log1p((s1 + s2) / 2)\n",
    "    \n",
    "def get_compare_engine(drop=[]):\n",
    "    exact_match_features = ['marstat','mbp','fbp','rel','first_nysiis','last_nysiis']\n",
    "    exact_match_features = [feat for feat in exact_match_features if feat not in drop]\n",
    "    c = rl.Compare() # declare comparison object\n",
    "    if 'res' not in drop:\n",
    "        c.geo('res_lat','res_lon','res_lat','res_lon',method = 'exp',scale=500)\n",
    "    if 'bp' not in drop:\n",
    "        c.geo('bp_lat','bp_lon','bp_lat','bp_lon', method = 'exp',scale=500)\n",
    "    if 'first_jaro' not in drop:\n",
    "        c.string('first','first',method = 'jarowinkler')\n",
    "    if 'last_jaro' not in drop:\n",
    "        c.string('last','last', method = 'jarowinkler')\n",
    "    #c.string('first','first',method = 'qgram')\n",
    "    #c.string('last','last', method = 'qgram')\n",
    "    if 'birth_year' not in drop:\n",
    "        c.numeric('birth_year','birth_year', method = 'lin', scale = 1, offset = 1)\n",
    "    if 'immigration' not in drop:\n",
    "        c.numeric('immigration','immigration', method = 'lin', scale = 1, offset = 1)\n",
    "    \n",
    "    vec_cols = [f'occ_vec{i}' for i in range(128)]\n",
    "    if 'occ' not in drop:\n",
    "        c.add(eucledian_distance(vec_cols,vec_cols))\n",
    "    if 'comm_first' not in drop:\n",
    "        c.add(commonality_weight('first_comm','first_comm'))\n",
    "    if 'comm_last' not in drop:\n",
    "        c.add(commonality_weight('last_comm','last_comm'))    \n",
    "    for col in exact_match_features:\n",
    "        c.exact(col,col)\n",
    "    return c"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load the training data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get the training set.\n",
    "df = pd.read_csv(trainPath)\n",
    "\n",
    "# Get the full data using SQL.\n",
    "sql1910 = RecordDB('compiled_1910','ark1910','rec_db')\n",
    "sql1920 = RecordDB('compiled_1920','ark1920','rec_db')\n",
    "rec1910 = sql1910.get_records(df['ark1910'].drop_duplicates()).set_index('index')\n",
    "rec1920 = sql1920.get_records(df['ark1920'].drop_duplicates()).set_index('index')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False    0.931924\n",
       "True     0.068076\n",
       "dtype: float64"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Create the truth value.\n",
    "pairs = pd.MultiIndex.from_arrays((df['ark1910'],df['ark1920']))\n",
    "y = df['ark1920']==df['true_ark_1920']\n",
    "y.value_counts(normalize=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "rec1910.index = rec1910.index_\n",
    "rec1920.index = rec1920.index_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "c = get_compare_engine(drop=['occ','first_nysiis','last_nysiis','res'])\n",
    "X = c.compute(pairs,rec1910,rec1920)\n",
    "X.columns=['bp','first_jaro','last_jaro','birth_year','immigration','first_comm',\n",
    "           'last_comm','marstat','mbp','fbp','rel']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>bp</th>\n",
       "      <th>first_jaro</th>\n",
       "      <th>last_jaro</th>\n",
       "      <th>birth_year</th>\n",
       "      <th>immigration</th>\n",
       "      <th>first_comm</th>\n",
       "      <th>last_comm</th>\n",
       "      <th>marstat</th>\n",
       "      <th>mbp</th>\n",
       "      <th>fbp</th>\n",
       "      <th>rel</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>213217.000000</td>\n",
       "      <td>213217.000000</td>\n",
       "      <td>213217.000000</td>\n",
       "      <td>213217.000000</td>\n",
       "      <td>213217.000000</td>\n",
       "      <td>213099.000000</td>\n",
       "      <td>212194.000000</td>\n",
       "      <td>213217.000000</td>\n",
       "      <td>213217.000000</td>\n",
       "      <td>213217.000000</td>\n",
       "      <td>213217.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>0.999991</td>\n",
       "      <td>0.919006</td>\n",
       "      <td>0.830371</td>\n",
       "      <td>0.481066</td>\n",
       "      <td>0.027688</td>\n",
       "      <td>0.078902</td>\n",
       "      <td>0.108761</td>\n",
       "      <td>0.735950</td>\n",
       "      <td>0.643457</td>\n",
       "      <td>0.624734</td>\n",
       "      <td>0.695615</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>0.003063</td>\n",
       "      <td>0.155184</td>\n",
       "      <td>0.172934</td>\n",
       "      <td>0.443577</td>\n",
       "      <td>0.154307</td>\n",
       "      <td>0.015181</td>\n",
       "      <td>0.044535</td>\n",
       "      <td>0.440827</td>\n",
       "      <td>0.478979</td>\n",
       "      <td>0.484193</td>\n",
       "      <td>0.460147</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.068960</td>\n",
       "      <td>0.072193</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.885714</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.071743</td>\n",
       "      <td>0.086103</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.866667</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.076312</td>\n",
       "      <td>0.096981</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.082698</td>\n",
       "      <td>0.115864</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.442695</td>\n",
       "      <td>1.091357</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                  bp     first_jaro      last_jaro     birth_year  \\\n",
       "count  213217.000000  213217.000000  213217.000000  213217.000000   \n",
       "mean        0.999991       0.919006       0.830371       0.481066   \n",
       "std         0.003063       0.155184       0.172934       0.443577   \n",
       "min         0.000000       0.000000       0.000000       0.000000   \n",
       "25%         1.000000       0.885714       0.666667       0.000000   \n",
       "50%         1.000000       1.000000       0.866667       0.500000   \n",
       "75%         1.000000       1.000000       1.000000       1.000000   \n",
       "max         1.000000       1.000000       1.000000       1.000000   \n",
       "\n",
       "         immigration     first_comm      last_comm        marstat  \\\n",
       "count  213217.000000  213099.000000  212194.000000  213217.000000   \n",
       "mean        0.027688       0.078902       0.108761       0.735950   \n",
       "std         0.154307       0.015181       0.044535       0.440827   \n",
       "min         0.000000       0.068960       0.072193       0.000000   \n",
       "25%         0.000000       0.071743       0.086103       0.000000   \n",
       "50%         0.000000       0.076312       0.096981       1.000000   \n",
       "75%         0.000000       0.082698       0.115864       1.000000   \n",
       "max         1.000000       1.442695       1.091357       1.000000   \n",
       "\n",
       "                 mbp            fbp            rel  \n",
       "count  213217.000000  213217.000000  213217.000000  \n",
       "mean        0.643457       0.624734       0.695615  \n",
       "std         0.478979       0.484193       0.460147  \n",
       "min         0.000000       0.000000       0.000000  \n",
       "25%         0.000000       0.000000       0.000000  \n",
       "50%         1.000000       1.000000       1.000000  \n",
       "75%         1.000000       1.000000       1.000000  \n",
       "max         1.000000       1.000000       1.000000  "
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Loading the test data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>bp</th>\n",
       "      <th>first_jaro</th>\n",
       "      <th>last_jaro</th>\n",
       "      <th>birth_year</th>\n",
       "      <th>immigration</th>\n",
       "      <th>first_comm</th>\n",
       "      <th>last_comm</th>\n",
       "      <th>marstat</th>\n",
       "      <th>mbp</th>\n",
       "      <th>fbp</th>\n",
       "      <th>rel</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>91379.000000</td>\n",
       "      <td>91379.000000</td>\n",
       "      <td>91379.000000</td>\n",
       "      <td>91379.000000</td>\n",
       "      <td>91379.000000</td>\n",
       "      <td>91339.000000</td>\n",
       "      <td>90916.000000</td>\n",
       "      <td>91379.000000</td>\n",
       "      <td>91379.000000</td>\n",
       "      <td>91379.000000</td>\n",
       "      <td>91379.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>0.999989</td>\n",
       "      <td>0.918454</td>\n",
       "      <td>0.830825</td>\n",
       "      <td>0.478956</td>\n",
       "      <td>0.028765</td>\n",
       "      <td>0.078953</td>\n",
       "      <td>0.108448</td>\n",
       "      <td>0.734315</td>\n",
       "      <td>0.646297</td>\n",
       "      <td>0.627617</td>\n",
       "      <td>0.691505</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>0.003308</td>\n",
       "      <td>0.156634</td>\n",
       "      <td>0.172951</td>\n",
       "      <td>0.443120</td>\n",
       "      <td>0.157514</td>\n",
       "      <td>0.015576</td>\n",
       "      <td>0.043669</td>\n",
       "      <td>0.441700</td>\n",
       "      <td>0.478121</td>\n",
       "      <td>0.483442</td>\n",
       "      <td>0.461875</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.068960</td>\n",
       "      <td>0.072193</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.883333</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.071743</td>\n",
       "      <td>0.086026</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.866667</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.076323</td>\n",
       "      <td>0.096981</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.082766</td>\n",
       "      <td>0.115759</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.442695</td>\n",
       "      <td>1.442695</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                 bp    first_jaro     last_jaro    birth_year   immigration  \\\n",
       "count  91379.000000  91379.000000  91379.000000  91379.000000  91379.000000   \n",
       "mean       0.999989      0.918454      0.830825      0.478956      0.028765   \n",
       "std        0.003308      0.156634      0.172951      0.443120      0.157514   \n",
       "min        0.000000      0.000000      0.000000      0.000000      0.000000   \n",
       "25%        1.000000      0.883333      0.666667      0.000000      0.000000   \n",
       "50%        1.000000      1.000000      0.866667      0.500000      0.000000   \n",
       "75%        1.000000      1.000000      1.000000      1.000000      0.000000   \n",
       "max        1.000000      1.000000      1.000000      1.000000      1.000000   \n",
       "\n",
       "         first_comm     last_comm       marstat           mbp           fbp  \\\n",
       "count  91339.000000  90916.000000  91379.000000  91379.000000  91379.000000   \n",
       "mean       0.078953      0.108448      0.734315      0.646297      0.627617   \n",
       "std        0.015576      0.043669      0.441700      0.478121      0.483442   \n",
       "min        0.068960      0.072193      0.000000      0.000000      0.000000   \n",
       "25%        0.071743      0.086026      0.000000      0.000000      0.000000   \n",
       "50%        0.076323      0.096981      1.000000      1.000000      1.000000   \n",
       "75%        0.082766      0.115759      1.000000      1.000000      1.000000   \n",
       "max        1.442695      1.442695      1.000000      1.000000      1.000000   \n",
       "\n",
       "                rel  \n",
       "count  91379.000000  \n",
       "mean       0.691505  \n",
       "std        0.461875  \n",
       "min        0.000000  \n",
       "25%        0.000000  \n",
       "50%        1.000000  \n",
       "75%        1.000000  \n",
       "max        1.000000  "
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Load in the test data.\n",
    "val = pd.read_csv(testPath)\n",
    "val.columns = ['ark1910','ark1920','true_ark1920']\n",
    "\n",
    "val['truth'] = val['ark1920']==val['true_ark1920']\n",
    "pairs = pd.MultiIndex.from_arrays((val['ark1910'],val['ark1920']))\n",
    "\n",
    "recb = sql1920.get_records(val['ark1920'].drop_duplicates().tolist()).set_index('index')\n",
    "reca = sql1910.get_records(val['ark1910'].drop_duplicates().tolist()).set_index('index')\n",
    "reca.index=reca.index_\n",
    "recb.index=recb.index_\n",
    "\n",
    "test_X=c.compute(pairs,reca,recb)\n",
    "\n",
    "test_y = val['truth']\n",
    "test_X.columns=['bp','first_jaro','last_jaro','birth_year','immigration','first_comm',\n",
    "           'last_comm','marstat','mbp','fbp','rel']\n",
    "\n",
    "test_X.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train using three algorithms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train_recall: 0.882190837065105\n",
      "train_precision: 0.19571430754887126\n",
      "\n",
      "val recall: 0.8731511254019293\n",
      "val precision: 0.19463159403669725\n",
      "\n",
      "train_f1_score: 0.3203572590127843\n",
      "test_f1_score: 0.3183096940569687\n"
     ]
    }
   ],
   "source": [
    "# Train on nearest centroid.\n",
    "from sklearn.neighbors import NearestCentroid\n",
    "model = NearestCentroid()\n",
    "model.fit(X.fillna(X.mean()),y)\n",
    "\n",
    "y_pred_val = model.predict(test_X.fillna(X.mean()))\n",
    "y_pred = model.predict(X.fillna(X.mean()))\n",
    "\n",
    "print(f'train_recall: {recall_score(y,y_pred)}')\n",
    "print(f'train_precision: {precision_score(y,y_pred)}\\n')\n",
    "print(f'val recall: {recall_score(test_y,y_pred_val)}')\n",
    "print(f'val precision: {precision_score(test_y,y_pred_val)}\\n')\n",
    "print(f'train_f1_score: {f1_score(y,y_pred)}')\n",
    "print(f'test_f1_score: {f1_score(test_y, y_pred_val)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train_recall: 0.5267654150878401\n",
      "train_precision: 0.8222389504247769\n",
      "\n",
      "val recall: 0.5290996784565917\n",
      "val precision: 0.8186567164179105\n",
      "\n",
      "train_f1_score: 0.642143277063912\n",
      "test_f1_score: 0.6427734375\n"
     ]
    }
   ],
   "source": [
    "# Train using Logistic Regression\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "model = LogisticRegression(max_iter=300)\n",
    "model.fit(X.fillna(X.mean()),y)\n",
    "\n",
    "# Predict\n",
    "y_pred_val = model.predict(test_X.fillna(X.mean()))\n",
    "y_pred = model.predict(X.fillna(X.mean()))\n",
    "\n",
    "# Print stats.\n",
    "print(f'train_recall: {recall_score(y,y_pred)}')\n",
    "print(f'train_precision: {precision_score(y,y_pred)}\\n')\n",
    "print(f'val recall: {recall_score(test_y,y_pred_val)}')\n",
    "print(f'val precision: {precision_score(test_y,y_pred_val)}\\n')\n",
    "print(f'train_f1_score: {f1_score(y,y_pred)}')\n",
    "print(f'test_f1_score: {f1_score(test_y, y_pred_val)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train_recall: 0.7466758525663107\n",
      "train_precision: 0.8477784730913642\n",
      "\n",
      "test_recall: 0.7138263665594855\n",
      "test_precision: 0.818735017517979\n",
      "\n",
      "train_f1_score: 0.7940217590387927\n",
      "test_f1_score: 0.7626900283432105\n"
     ]
    }
   ],
   "source": [
    "# Train using XGB.\n",
    "model = XGBClassifier()\n",
    "model.fit(X,y)\n",
    "\n",
    "y_pred_val = model.predict(test_X)\n",
    "y_pred = model.predict(X)\n",
    "\n",
    "print(f'train_recall: {recall_score(y,y_pred)}')\n",
    "print(f'train_precision: {precision_score(y,y_pred)}\\n')\n",
    "print(f'test_recall: {recall_score(test_y,y_pred_val)}')\n",
    "print(f'test_precision: {precision_score(test_y,y_pred_val)}\\n')\n",
    "print(f'train_f1_score: {f1_score(y,y_pred)}')\n",
    "print(f'test_f1_score: {f1_score(test_y, y_pred_val)}')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Test micro-parameters for XGBoost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.7562705414288186 0.3 5 0 0\n",
      "0.7579979360165119 0.3 5 0 1\n",
      "0.7587987264435074 0.3 5 0.5 0\n",
      "0.761105880338954 0.3 5 0.5 1\n",
      "0.7593959155654711 0.3 6 0 0\n",
      "0.7626900283432105 0.3 6 0 1\n",
      "0.7614797013131921 0.3 6 0.5 0\n",
      "0.7623379967384775 0.3 6 0.5 1\n",
      "0.7633262260127933 0.3 7 0 0\n",
      "0.7627380339680906 0.3 7 0 1\n",
      "0.7651385562777969 0.3 7 0.5 0\n",
      "0.7606888869848342 0.3 7 0.5 1\n",
      "0.758086717136958 0.4 5 0 0\n",
      "0.7600827300930714 0.4 5 0 1\n",
      "0.7593226137529935 0.4 5 0.5 0\n",
      "0.7597736625514403 0.4 5 0.5 1\n",
      "0.7607435197817191 0.4 6 0 0\n",
      "0.7601230138390569 0.4 6 0 1\n",
      "0.7609272089641604 0.4 6 0.5 0\n",
      "0.7607414367472453 0.4 6 0.5 1\n",
      "0.7609864322894444 0.4 7 0 0\n",
      "0.7594351732991014 0.4 7 0 1\n",
      "0.7611927618723983 0.4 7 0.5 0\n",
      "0.7631220177232448 0.4 7 0.5 1\n",
      "0.7573264781491001 0.5 5 0 0\n",
      "0.7601678225875503 0.5 5 0 1\n",
      "0.7601988344189236 0.5 5 0.5 0\n",
      "0.7584549356223177 0.5 5 0.5 1\n",
      "0.760771649528342 0.5 6 0 0\n",
      "0.7605103176641835 0.5 6 0 1\n",
      "0.7581577158395649 0.5 6 0.5 0\n",
      "0.7629692832764505 0.5 6 0.5 1\n",
      "0.7572980312287849 0.5 7 0 0\n",
      "0.7630569992331941 0.5 7 0 1\n",
      "0.7566740350280564 0.5 7 0.5 0\n",
      "0.7601709401709401 0.5 7 0.5 1\n"
     ]
    }
   ],
   "source": [
    "# Check the following micro parameters.\n",
    "learning_rates=[.3,.4,.5]\n",
    "max_depth=[5,6,7]\n",
    "alpha_vals = [0,0.5]\n",
    "lambda_vals = [0,1]\n",
    "n_jobs=16\n",
    "\n",
    "\n",
    "for lr in learning_rates:\n",
    "    for depth in max_depth:\n",
    "        for alph in alpha_vals:\n",
    "            for lam in lambda_vals:\n",
    "                model = XGBClassifier(\n",
    "                    learning_rate=lr, max_depth=depth, n_jobs=n_jobs,\n",
    "                    reg_alpha=alph, reg_lambda=lam)\n",
    "                model.fit(X,y)\n",
    "                y_pred_val = model.predict(test_X)\n",
    "                print(f1_score(test_y, y_pred_val), lr, depth, alph, lam)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ReCreate and save our best model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "XGBClassifier(base_score=0.5, booster='gbtree', colsample_bylevel=1,\n",
       "              colsample_bynode=1, colsample_bytree=1, gamma=0, gpu_id=-1,\n",
       "              importance_type='gain', interaction_constraints='',\n",
       "              learning_rate=0.3, max_delta_step=0, max_depth=7,\n",
       "              min_child_weight=1, missing=nan, monotone_constraints='()',\n",
       "              n_estimators=100, n_jobs=16, num_parallel_tree=1,\n",
       "              objective='binary:logistic', random_state=0, reg_alpha=0.5,\n",
       "              reg_lambda=0, scale_pos_weight=1, subsample=1,\n",
       "              tree_method='exact', validate_parameters=1, verbosity=None)"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = XGBClassifier(learning_rate=0.3, max_depth=7, n_jobs=n_jobs,\n",
    "                    reg_alpha=0.5, reg_lambda=0)\n",
    "model.fit(X,y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(84160, 999, 1747, 4473)"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_pred_val = model.predict(test_X)\n",
    "y_pred = model.predict(X)\n",
    "tn, fp, fn, tp = confusion_matrix(test_y,y_pred_val).ravel()\n",
    "tn, fp, fn, tp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save the model.\n",
    "import pickle\n",
    "pickle.dump(model, open(\"model_1910_1920_no_res.dat\", \"wb\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([False, False, False, ..., False, False, False])"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Load the model\n",
    "loaded_model = pickle.load(open(\"model_1910_1920_no_res.dat\", \"rb\"))\n",
    "loaded_model.predict(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
