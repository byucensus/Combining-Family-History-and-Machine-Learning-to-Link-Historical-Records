{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from splycer.blocker import BlockDB\n",
    "from splycer.record_set import RecordDB\n",
    "from splycer.pairs_set import PairsDB\n",
    "from splycer.feature_engineer import FeatureEngineer\n",
    "import recordlinkage as rl\n",
    "import pyodbc\n",
    "import numpy as np\n",
    "from xgboost import XGBClassifier\n",
    "from sklearn.metrics import confusion_matrix, precision_score, recall_score, f1_score\n",
    "import pickle as pkl\n",
    "from tqdm import tqdm\n",
    "\n",
    "# Set up a database connection\n",
    "import turbodbc\n",
    "conn = turbodbc.connect('rec_db')\n",
    "\n",
    "import os.path\n",
    "basePath = r'R:\\JoePriceResearch\\record_linking\\projects\\deep_learning\\paper_RR\\CensusTree_2020\\final'\n",
    "trainPath = os.path.abspath(os.path.join(basePath, '2-split_train_test', 'train_1900_1910.csv'))\n",
    "testPath = os.path.abspath(os.path.join(basePath, '2-split_train_test', 'test_1900_1910.csv'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create the class for comparing features."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from recordlinkage.base import BaseCompareFeature\n",
    "\n",
    "class eucledian_distance(BaseCompareFeature):\n",
    "    def __init__(self, left_on, right_on):\n",
    "        super(eucledian_distance, self).__init__(left_on, right_on)\n",
    "        self.n = len(left_on)\n",
    "    def _compute_vectorized(self,*args):\n",
    "        s1 = args[:self.n]\n",
    "        s2 = args[self.n:]\n",
    "        return np.linalg.norm(np.array(s1)-np.array(s2),ord=2,axis=0)\n",
    "    \n",
    "class commonality_weight(BaseCompareFeature):\n",
    "    def __init__(self,left_on,right_on):\n",
    "        super(commonality_weight, self).__init__(left_on, right_on)\n",
    "    def _compute_vectorized(self,s1,s2):\n",
    "        return 1 / np.log1p((s1 + s2) / 2)\n",
    "    \n",
    "def get_compare_engine(drop=[]):\n",
    "    exact_match_features = ['marstat','mbp','fbp','rel','first_nysiis','last_nysiis']\n",
    "    exact_match_features = [feat for feat in exact_match_features if feat not in drop]\n",
    "    c = rl.Compare() # declare comparison object\n",
    "    if 'res' not in drop:\n",
    "        c.geo('res_lat','res_lon','res_lat','res_lon',method = 'exp',scale=500)\n",
    "    if 'bp' not in drop:\n",
    "        c.geo('bp_lat','bp_lon','bp_lat','bp_lon', method = 'exp',scale=500)\n",
    "    if 'first_jaro' not in drop:\n",
    "        c.string('first','first',method = 'jarowinkler')\n",
    "    if 'last_jaro' not in drop:\n",
    "        c.string('last','last', method = 'jarowinkler')\n",
    "    #c.string('first','first',method = 'qgram')\n",
    "    #c.string('last','last', method = 'qgram')\n",
    "    if 'birth_year' not in drop:\n",
    "        c.numeric('birth_year','birth_year', method = 'lin', scale = 1, offset = 1)\n",
    "    if 'immigration' not in drop:\n",
    "        c.numeric('immigration','immigration', method = 'lin', scale = 1, offset = 1)\n",
    "    \n",
    "    vec_cols = [f'occ_vec{i}' for i in range(128)]\n",
    "    if 'occ' not in drop:\n",
    "        c.add(eucledian_distance(vec_cols,vec_cols))\n",
    "    if 'comm_first' not in drop:\n",
    "        c.add(commonality_weight('first_comm','first_comm'))\n",
    "    if 'comm_last' not in drop:\n",
    "        c.add(commonality_weight('last_comm','last_comm'))    \n",
    "    for col in exact_match_features:\n",
    "        c.exact(col,col)\n",
    "    return c"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load the training data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get the training set.\n",
    "df = pd.read_csv(trainPath)\n",
    "\n",
    "# Get the full data using SQL.\n",
    "sql1900 = RecordDB('compiled_1900','ark1900','rec_db')\n",
    "sql1910 = RecordDB('compiled_1910','ark1910','rec_db')\n",
    "rec1900 = sql1900.get_records(df['ark1900'].drop_duplicates()).set_index('index')\n",
    "rec1910 = sql1910.get_records(df['ark1910'].drop_duplicates()).set_index('index')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False    0.891553\n",
       "True     0.108447\n",
       "dtype: float64"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Create the truth value.\n",
    "pairs = pd.MultiIndex.from_arrays((df['ark1900'],df['ark1910']))\n",
    "y = df['ark1910']==df['true_ark_1910']\n",
    "y.value_counts(normalize=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "rec1900.index = rec1900.index_\n",
    "rec1910.index = rec1910.index_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "c = get_compare_engine(drop=['occ','first_nysiis','last_nysiis'])\n",
    "X = c.compute(pairs,rec1900,rec1910)\n",
    "X.columns=['res','bp','first_jaro','last_jaro','birth_year','immigration','first_comm',\n",
    "           'last_comm','marstat','mbp','fbp','rel']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>res</th>\n",
       "      <th>bp</th>\n",
       "      <th>first_jaro</th>\n",
       "      <th>last_jaro</th>\n",
       "      <th>birth_year</th>\n",
       "      <th>immigration</th>\n",
       "      <th>first_comm</th>\n",
       "      <th>last_comm</th>\n",
       "      <th>marstat</th>\n",
       "      <th>mbp</th>\n",
       "      <th>fbp</th>\n",
       "      <th>rel</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>221390.000000</td>\n",
       "      <td>221390.000000</td>\n",
       "      <td>221390.000000</td>\n",
       "      <td>221390.000000</td>\n",
       "      <td>221390.000000</td>\n",
       "      <td>221390.000000</td>\n",
       "      <td>221375.000000</td>\n",
       "      <td>221365.000000</td>\n",
       "      <td>221390.000000</td>\n",
       "      <td>221390.000000</td>\n",
       "      <td>221390.000000</td>\n",
       "      <td>221390.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>0.583953</td>\n",
       "      <td>0.999968</td>\n",
       "      <td>0.928740</td>\n",
       "      <td>0.923849</td>\n",
       "      <td>0.614673</td>\n",
       "      <td>0.057932</td>\n",
       "      <td>0.077981</td>\n",
       "      <td>0.100075</td>\n",
       "      <td>0.749451</td>\n",
       "      <td>0.715050</td>\n",
       "      <td>0.698026</td>\n",
       "      <td>0.712679</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>0.330974</td>\n",
       "      <td>0.005623</td>\n",
       "      <td>0.165150</td>\n",
       "      <td>0.128159</td>\n",
       "      <td>0.413224</td>\n",
       "      <td>0.219378</td>\n",
       "      <td>0.018295</td>\n",
       "      <td>0.033077</td>\n",
       "      <td>0.433330</td>\n",
       "      <td>0.451391</td>\n",
       "      <td>0.459115</td>\n",
       "      <td>0.452514</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.455556</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.069286</td>\n",
       "      <td>0.072734</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>0.289866</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.880000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.069342</td>\n",
       "      <td>0.080787</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>0.657234</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.073740</td>\n",
       "      <td>0.092054</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>0.868035</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.081179</td>\n",
       "      <td>0.107302</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.442695</td>\n",
       "      <td>1.091357</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                 res             bp     first_jaro      last_jaro  \\\n",
       "count  221390.000000  221390.000000  221390.000000  221390.000000   \n",
       "mean        0.583953       0.999968       0.928740       0.923849   \n",
       "std         0.330974       0.005623       0.165150       0.128159   \n",
       "min         0.000000       0.000000       0.455556       0.000000   \n",
       "25%         0.289866       1.000000       1.000000       0.880000   \n",
       "50%         0.657234       1.000000       1.000000       1.000000   \n",
       "75%         0.868035       1.000000       1.000000       1.000000   \n",
       "max         1.000000       1.000000       1.000000       1.000000   \n",
       "\n",
       "          birth_year    immigration     first_comm      last_comm  \\\n",
       "count  221390.000000  221390.000000  221375.000000  221365.000000   \n",
       "mean        0.614673       0.057932       0.077981       0.100075   \n",
       "std         0.413224       0.219378       0.018295       0.033077   \n",
       "min         0.000000       0.000000       0.069286       0.072734   \n",
       "25%         0.000000       0.000000       0.069342       0.080787   \n",
       "50%         0.500000       0.000000       0.073740       0.092054   \n",
       "75%         1.000000       0.000000       0.081179       0.107302   \n",
       "max         1.000000       1.000000       1.442695       1.091357   \n",
       "\n",
       "             marstat            mbp            fbp            rel  \n",
       "count  221390.000000  221390.000000  221390.000000  221390.000000  \n",
       "mean        0.749451       0.715050       0.698026       0.712679  \n",
       "std         0.433330       0.451391       0.459115       0.452514  \n",
       "min         0.000000       0.000000       0.000000       0.000000  \n",
       "25%         0.000000       0.000000       0.000000       0.000000  \n",
       "50%         1.000000       1.000000       1.000000       1.000000  \n",
       "75%         1.000000       1.000000       1.000000       1.000000  \n",
       "max         1.000000       1.000000       1.000000       1.000000  "
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Loading the test data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>res</th>\n",
       "      <th>bp</th>\n",
       "      <th>first_jaro</th>\n",
       "      <th>last_jaro</th>\n",
       "      <th>birth_year</th>\n",
       "      <th>immigration</th>\n",
       "      <th>first_comm</th>\n",
       "      <th>last_comm</th>\n",
       "      <th>marstat</th>\n",
       "      <th>mbp</th>\n",
       "      <th>fbp</th>\n",
       "      <th>rel</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>94882.000000</td>\n",
       "      <td>94882.000000</td>\n",
       "      <td>94882.000000</td>\n",
       "      <td>94882.000000</td>\n",
       "      <td>94882.000000</td>\n",
       "      <td>94882.000000</td>\n",
       "      <td>94866.000000</td>\n",
       "      <td>94870.000000</td>\n",
       "      <td>94882.000000</td>\n",
       "      <td>94882.000000</td>\n",
       "      <td>94882.000000</td>\n",
       "      <td>94882.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>0.584409</td>\n",
       "      <td>0.999937</td>\n",
       "      <td>0.928245</td>\n",
       "      <td>0.924030</td>\n",
       "      <td>0.612888</td>\n",
       "      <td>0.057919</td>\n",
       "      <td>0.078062</td>\n",
       "      <td>0.100241</td>\n",
       "      <td>0.749405</td>\n",
       "      <td>0.717576</td>\n",
       "      <td>0.700986</td>\n",
       "      <td>0.712664</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>0.330946</td>\n",
       "      <td>0.007952</td>\n",
       "      <td>0.165962</td>\n",
       "      <td>0.127848</td>\n",
       "      <td>0.413282</td>\n",
       "      <td>0.219466</td>\n",
       "      <td>0.021201</td>\n",
       "      <td>0.033681</td>\n",
       "      <td>0.433358</td>\n",
       "      <td>0.450181</td>\n",
       "      <td>0.457828</td>\n",
       "      <td>0.452522</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.069286</td>\n",
       "      <td>0.072734</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>0.290949</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.880000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.069342</td>\n",
       "      <td>0.080912</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>0.657936</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.073740</td>\n",
       "      <td>0.092193</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>0.868460</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.081179</td>\n",
       "      <td>0.107302</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.442695</td>\n",
       "      <td>1.091357</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                res            bp    first_jaro     last_jaro    birth_year  \\\n",
       "count  94882.000000  94882.000000  94882.000000  94882.000000  94882.000000   \n",
       "mean       0.584409      0.999937      0.928245      0.924030      0.612888   \n",
       "std        0.330946      0.007952      0.165962      0.127848      0.413282   \n",
       "min        0.000000      0.000000      0.000000      0.000000      0.000000   \n",
       "25%        0.290949      1.000000      1.000000      0.880000      0.000000   \n",
       "50%        0.657936      1.000000      1.000000      1.000000      0.500000   \n",
       "75%        0.868460      1.000000      1.000000      1.000000      1.000000   \n",
       "max        1.000000      1.000000      1.000000      1.000000      1.000000   \n",
       "\n",
       "        immigration    first_comm     last_comm       marstat           mbp  \\\n",
       "count  94882.000000  94866.000000  94870.000000  94882.000000  94882.000000   \n",
       "mean       0.057919      0.078062      0.100241      0.749405      0.717576   \n",
       "std        0.219466      0.021201      0.033681      0.433358      0.450181   \n",
       "min        0.000000      0.069286      0.072734      0.000000      0.000000   \n",
       "25%        0.000000      0.069342      0.080912      0.000000      0.000000   \n",
       "50%        0.000000      0.073740      0.092193      1.000000      1.000000   \n",
       "75%        0.000000      0.081179      0.107302      1.000000      1.000000   \n",
       "max        1.000000      1.442695      1.091357      1.000000      1.000000   \n",
       "\n",
       "                fbp           rel  \n",
       "count  94882.000000  94882.000000  \n",
       "mean       0.700986      0.712664  \n",
       "std        0.457828      0.452522  \n",
       "min        0.000000      0.000000  \n",
       "25%        0.000000      0.000000  \n",
       "50%        1.000000      1.000000  \n",
       "75%        1.000000      1.000000  \n",
       "max        1.000000      1.000000  "
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Load in the test data.\n",
    "val = pd.read_csv(testPath)\n",
    "val.columns = ['ark1900','ark1910','true_ark1910']\n",
    "\n",
    "val['truth'] = val['ark1910']==val['true_ark1910']\n",
    "pairs = pd.MultiIndex.from_arrays((val['ark1900'],val['ark1910']))\n",
    "\n",
    "recb = sql1910.get_records(val['ark1910'].drop_duplicates().tolist()).set_index('index')\n",
    "reca = sql1900.get_records(val['ark1900'].drop_duplicates().tolist()).set_index('index')\n",
    "reca.index=reca.index_\n",
    "recb.index=recb.index_\n",
    "\n",
    "test_X=c.compute(pairs,reca,recb)\n",
    "\n",
    "test_y = val['truth']\n",
    "test_X.columns=['res','bp','first_jaro','last_jaro','birth_year','immigration','first_comm',\n",
    "           'last_comm','marstat','mbp','fbp','rel']\n",
    "\n",
    "test_X.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train using three algorithms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train_recall: 0.821317006122704\n",
      "train_precision: 0.27007519208908004\n",
      "\n",
      "val recall: 0.8162182644941266\n",
      "val precision: 0.275324343324599\n",
      "\n",
      "train_f1_score: 0.4064851270845788\n",
      "test_f1_score: 0.4117562724014337\n"
     ]
    }
   ],
   "source": [
    "# Train on nearest centroid.\n",
    "from sklearn.neighbors import NearestCentroid\n",
    "model = NearestCentroid()\n",
    "model.fit(X.fillna(X.mean()),y)\n",
    "\n",
    "y_pred_val = model.predict(test_X.fillna(X.mean()))\n",
    "y_pred = model.predict(X.fillna(X.mean()))\n",
    "\n",
    "print(f'train_recall: {recall_score(y,y_pred)}')\n",
    "print(f'train_precision: {precision_score(y,y_pred)}\\n')\n",
    "print(f'val recall: {recall_score(test_y,y_pred_val)}')\n",
    "print(f'val precision: {precision_score(test_y,y_pred_val)}\\n')\n",
    "print(f'train_f1_score: {f1_score(y,y_pred)}')\n",
    "print(f'test_f1_score: {f1_score(test_y, y_pred_val)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train_recall: 0.6537964929817985\n",
      "train_precision: 0.8386941654199616\n",
      "\n",
      "val recall: 0.650909435392194\n",
      "val precision: 0.8455574698498647\n",
      "\n",
      "train_f1_score: 0.7347922761849035\n",
      "test_f1_score: 0.7355743496413661\n"
     ]
    }
   ],
   "source": [
    "# Train using Logistic Regression\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "model = LogisticRegression(max_iter=300)\n",
    "model.fit(X.fillna(X.mean()),y)\n",
    "\n",
    "# Predict\n",
    "y_pred_val = model.predict(test_X.fillna(X.mean()))\n",
    "y_pred = model.predict(X.fillna(X.mean()))\n",
    "\n",
    "# Print stats.\n",
    "print(f'train_recall: {recall_score(y,y_pred)}')\n",
    "print(f'train_precision: {precision_score(y,y_pred)}\\n')\n",
    "print(f'val recall: {recall_score(test_y,y_pred_val)}')\n",
    "print(f'val precision: {precision_score(test_y,y_pred_val)}\\n')\n",
    "print(f'train_f1_score: {f1_score(y,y_pred)}')\n",
    "print(f'test_f1_score: {f1_score(test_y, y_pred_val)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train_recall: 0.8448914990212004\n",
      "train_precision: 0.888679575922194\n",
      "\n",
      "test_recall: 0.8226600985221675\n",
      "test_precision: 0.8777036587831009\n",
      "\n",
      "train_f1_score: 0.8662325184157148\n",
      "test_f1_score: 0.8492909535452322\n"
     ]
    }
   ],
   "source": [
    "# Train using XGB.\n",
    "model = XGBClassifier()\n",
    "model.fit(X,y)\n",
    "\n",
    "y_pred_val = model.predict(test_X)\n",
    "y_pred = model.predict(X)\n",
    "\n",
    "print(f'train_recall: {recall_score(y,y_pred)}')\n",
    "print(f'train_precision: {precision_score(y,y_pred)}\\n')\n",
    "print(f'test_recall: {recall_score(test_y,y_pred_val)}')\n",
    "print(f'test_precision: {precision_score(test_y,y_pred_val)}\\n')\n",
    "print(f'train_f1_score: {f1_score(y,y_pred)}')\n",
    "print(f'test_f1_score: {f1_score(test_y, y_pred_val)}')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Test micro-parameters for XGBoost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.8480516937536715 0.3 5 0 0\n",
      "0.8460071397134333 0.3 5 0 1\n",
      "0.8480516937536715 0.3 5 0.5 0\n",
      "0.8480969365319782 0.3 5 0.5 1\n",
      "0.8465634311953495 0.3 6 0 0\n",
      "0.8492909535452322 0.3 6 0 1\n",
      "0.8473353162026428 0.3 6 0.5 0\n",
      "0.8487185745667563 0.3 6 0.5 1\n",
      "0.84819206558337 0.4 5 0 0\n",
      "0.8476898981989036 0.4 5 0 1\n",
      "0.8483781006898575 0.4 5 0.5 0\n",
      "0.8483041735900694 0.4 5 0.5 1\n",
      "0.8487038031538349 0.4 6 0 0\n",
      "0.8499706974018362 0.4 6 0 1\n",
      "0.849599843841499 0.4 6 0.5 0\n",
      "0.8508621953006692 0.4 6 0.5 1\n"
     ]
    }
   ],
   "source": [
    "# Check the following micro parameters.\n",
    "learning_rates=[.3,.4]\n",
    "max_depth=[5,6]\n",
    "alpha_vals = [0,0.5]\n",
    "lambda_vals = [0,1]\n",
    "n_jobs=16\n",
    "\n",
    "\n",
    "for lr in learning_rates:\n",
    "    for depth in max_depth:\n",
    "        for alph in alpha_vals:\n",
    "            for lam in lambda_vals:\n",
    "                model = XGBClassifier(\n",
    "                    learning_rate=lr, max_depth=depth, n_jobs=n_jobs,\n",
    "                    reg_alpha=alph, reg_lambda=lam)\n",
    "                model.fit(X,y)\n",
    "                y_pred_val = model.predict(test_X)\n",
    "                print(f1_score(test_y, y_pred_val), lr, depth, alph, lam)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ReCreate and save our best model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "XGBClassifier(base_score=0.5, booster='gbtree', colsample_bylevel=1,\n",
       "              colsample_bynode=1, colsample_bytree=1, gamma=0, gpu_id=-1,\n",
       "              importance_type='gain', interaction_constraints='',\n",
       "              learning_rate=0.4, max_delta_step=0, max_depth=6,\n",
       "              min_child_weight=1, missing=nan, monotone_constraints='()',\n",
       "              n_estimators=100, n_jobs=16, num_parallel_tree=1,\n",
       "              objective='binary:logistic', random_state=0, reg_alpha=0.5,\n",
       "              reg_lambda=1, scale_pos_weight=1, subsample=1,\n",
       "              tree_method='exact', validate_parameters=1, verbosity=None)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = XGBClassifier(learning_rate=0.4, max_depth=6, n_jobs=n_jobs,\n",
    "                    reg_alpha=0.5, reg_lambda=1)\n",
    "model.fit(X,y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(83120, 1206, 1847, 8709)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_pred_val = model.predict(test_X)\n",
    "y_pred = model.predict(X)\n",
    "tn, fp, fn, tp = confusion_matrix(test_y,y_pred_val).ravel()\n",
    "tn, fp, fn, tp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save the model.\n",
    "import pickle\n",
    "pickle.dump(model, open(\"model_1900_1910.dat\", \"wb\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([False, False, False, ..., False, False, False])"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Load the model\n",
    "loaded_model = pickle.load(open(\"model_1900_1910.dat\", \"rb\"))\n",
    "loaded_model.predict(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
